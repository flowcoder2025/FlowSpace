"use client"

/**
 * LiveKitMediaContext
 *
 * LiveKit ë¯¸ë””ì–´ ìƒíƒœë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
 * @livekit/components-reactì˜ useTracks í›…ì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë™ ìƒíƒœ ìë™ ë™ê¸°í™”
 */

import { createContext, useContext, ReactNode, useMemo, useCallback, useState, useEffect, useRef } from "react"
import {
  useLocalParticipant,
  useParticipants,
  useMaybeRoomContext,
  useConnectionState,
  useTracks,
} from "@livekit/components-react"
import {
  Track,
  ConnectionState,
  RemoteTrackPublication,
  RoomEvent,
  RemoteParticipant,
  Participant,
  TrackPublication,
  RemoteTrack,
} from "livekit-client"
import type { ParticipantTrack, MediaState } from "./types"

const IS_DEV = process.env.NODE_ENV === "development"

// ë¯¸ë””ì–´ ì—ëŸ¬ íƒ€ì…
export type MediaError = {
  type: "permission_denied" | "not_found" | "not_connected" | "unknown"
  message: string
}

// Screen share options
export interface ScreenShareOptions {
  /** ì‹œìŠ¤í…œ/íƒ­ ì˜¤ë””ì˜¤ í¬í•¨ ì—¬ë¶€ (ë¸Œë¼ìš°ì € íƒ­ ê³µìœ  ì‹œë§Œ ì§€ì›) */
  audio?: boolean
}

// Audio capture options type
export interface AudioCaptureOptionsInput {
  noiseSuppression?: boolean
  echoCancellation?: boolean
  autoGainControl?: boolean
  voiceIsolation?: boolean
  deviceId?: string
}

// Context value type
export interface LiveKitMediaContextValue {
  participantTracks: Map<string, ParticipantTrack>
  mediaState: MediaState
  mediaError: MediaError | null
  isAvailable: boolean
  localParticipantId: string | null
  localAudioTrack: MediaStreamTrack | null // VADìš© ë¡œì»¬ ë§ˆì´í¬ íŠ¸ë™
  toggleCamera: () => Promise<boolean>
  toggleMicrophone: () => Promise<boolean>
  toggleScreenShare: (options?: ScreenShareOptions) => Promise<boolean>
  /** VAD ê²Œì´íŠ¸ìš©: ë¡œì»¬ ë§ˆì´í¬ ë®¤íŠ¸/ì–¸ë®¤íŠ¸ (íŠ¸ë™ ìœ ì§€) - ë ˆê±°ì‹œ, setLocalAudioGated ì‚¬ìš© ê¶Œì¥ */
  setLocalMicrophoneMuted: (muted: boolean) => Promise<boolean>
  /** ğŸ“Œ ì†ŒìŠ¤ ë ˆë²¨ ì˜¤ë””ì˜¤ ê²Œì´íŠ¸: MediaStreamTrack.enabled ì§ì ‘ ì œì–´ */
  setLocalAudioGated: (gated: boolean) => boolean
  /** ğŸ“Œ AudioWorklet ì²˜ë¦¬ëœ íŠ¸ë™ìœ¼ë¡œ êµì²´ */
  replaceAudioTrackWithProcessed: (processedTrack: MediaStreamTrack) => Promise<boolean>
  /** ğŸ“Œ ì˜¤ë””ì˜¤ ì˜µì…˜ ë³€ê²½ ì‹œ ë§ˆì´í¬ ì¬ì‹œì‘ (ë™ì  ì ìš©) */
  restartMicrophoneWithOptions: (options: AudioCaptureOptionsInput) => Promise<boolean>
  /** ğŸ“Œ ì¹´ë©”ë¼ ì¥ì¹˜ ì „í™˜ (ì„¤ì • ë³€ê²½ ì‹œ ì‚¬ìš©) */
  switchCameraDevice: (deviceId: string) => Promise<boolean>
  /** ğŸ“Œ ë§ˆì´í¬ ì¥ì¹˜ ì „í™˜ (ì„¤ì • ë³€ê²½ ì‹œ ì‚¬ìš©) */
  switchMicrophoneDevice: (deviceId: string) => Promise<boolean>
  /** ğŸ“Œ ì¹´ë©”ë¼ ì„¤ì • ì¬ì ìš© (í•´ìƒë„/í”„ë ˆì„ë ˆì´íŠ¸ ë³€ê²½ ì‹œ ì¹´ë©”ë¼ ì¬ì‹œì‘) */
  restartCamera: () => Promise<boolean>
}

// Default value (when not in LiveKit context)
const defaultContextValue: LiveKitMediaContextValue = {
  participantTracks: new Map(),
  mediaState: {
    isCameraEnabled: false,
    isMicrophoneEnabled: false,
    isScreenShareEnabled: false,
  },
  mediaError: null,
  isAvailable: false,
  localParticipantId: null,
  localAudioTrack: null,
  toggleCamera: async () => false,
  toggleMicrophone: async () => false,
  toggleScreenShare: async () => false,
  setLocalMicrophoneMuted: async () => false,
  setLocalAudioGated: () => false,
  replaceAudioTrackWithProcessed: async () => false,
  restartMicrophoneWithOptions: async () => false,
  switchCameraDevice: async () => false,
  switchMicrophoneDevice: async () => false,
  restartCamera: async () => false,
}

// Create context
const LiveKitMediaContext = createContext<LiveKitMediaContextValue>(defaultContextValue)

/**
 * useLiveKitMedia - Context consumer hook
 * Always safe to call (returns defaults when not in LiveKit context)
 */
export function useLiveKitMedia(): LiveKitMediaContextValue {
  return useContext(LiveKitMediaContext)
}

/**
 * LiveKitMediaProvider - Provides default values when outside LiveKitRoom
 */
export function LiveKitMediaFallbackProvider({ children }: { children: ReactNode }) {
  return (
    <LiveKitMediaContext.Provider value={defaultContextValue}>
      {children}
    </LiveKitMediaContext.Provider>
  )
}

/**
 * LiveKitMediaInternalProvider - Uses LiveKit hooks (MUST be inside LiveKitRoom)
 *
 * í•µì‹¬: useTracks í›…ì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë™ ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ë™ê¸°í™”
 * - íŠ¸ë™ êµ¬ë…/í•´ì œ ìë™ ì¶”ì 
 * - mute/unmute ìƒíƒœ ìë™ ê°ì§€
 * - React ìƒíƒœì™€ LiveKit ì´ë²¤íŠ¸ ê°„ì˜ ë™ê¸°í™”ë¥¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì²˜ë¦¬
 */
export function LiveKitMediaInternalProvider({ children }: { children: ReactNode }) {
  const [mediaError, setMediaError] = useState<MediaError | null>(null)

  // Room context
  const room = useMaybeRoomContext()

  // ì—°ê²° ìƒíƒœ í™•ì¸
  const connectionState = useConnectionState(room)
  const isConnected = connectionState === ConnectionState.Connected

  // Local participant - reactive ê°’ë“¤ì„ ì§ì ‘ êµ¬ì¡° ë¶„í•´
  const {
    localParticipant,
    isCameraEnabled,
    isMicrophoneEnabled,
    isScreenShareEnabled,
  } = useLocalParticipant()

  // All participants (local + remote)
  const participants = useParticipants()

  // ğŸ”‘ í•µì‹¬: useTracks í›…ìœ¼ë¡œ êµ¬ë…ëœ íŠ¸ë™ë§Œ ìë™ ì¶”ì 
  // ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ íŠ¸ë™ êµ¬ë… ìƒíƒœ, mute ìƒíƒœ ë“±ì„ ìë™ìœ¼ë¡œ React ìƒíƒœì™€ ë™ê¸°í™”
  const tracks = useTracks(
    [
      { source: Track.Source.Camera, withPlaceholder: true },
      { source: Track.Source.Microphone, withPlaceholder: false },
      { source: Track.Source.ScreenShare, withPlaceholder: true },
    ],
    { onlySubscribed: false }
  )

  // ğŸ”§ Late Joiner ëŒ€ì‘: íŠ¸ë™ êµ¬ë… ê°•ì œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
  const [trackUpdateTrigger, setTrackUpdateTrigger] = useState(0)

  // ğŸ”‘ í•µì‹¬ ê°œì„ : TrackSubscribed ì´ë²¤íŠ¸ì—ì„œ ì§ì ‘ íŠ¸ë™ì„ ì €ì¥í•˜ëŠ” ref
  // useTracks í›…ì˜ React ìƒíƒœ ì—…ë°ì´íŠ¸ ì§€ì—° ë¬¸ì œë¥¼ ìš°íšŒ
  interface StoredTrackInfo {
    track: RemoteTrack
    publication: RemoteTrackPublication
    source: Track.Source
  }
  const subscribedTracksRef = useRef<Map<string, StoredTrackInfo>>(new Map())

  // ğŸ”‘ íŠ¸ë™ ì¤€ë¹„ ëŒ€ê¸° ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì  (ë¬´í•œ ë£¨í”„ ë°©ì§€)
  const trackReadyRetryCountRef = useRef<number>(0)
  const MAX_TRACK_READY_RETRIES = 30 // ìµœëŒ€ 30ë²ˆ (3ì´ˆ)

  // ğŸ”§ êµ¬ë… ë¡œì§: ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ë°©ì‹ìœ¼ë¡œ ì „ë©´ ê°œí¸
  useEffect(() => {
    if (!room || !isConnected) return

    const shouldSubscribeSource = (source: Track.Source) =>
      source === Track.Source.Camera ||
      source === Track.Source.ScreenShare ||
      source === Track.Source.Microphone

    // ğŸ”‘ ì´ë¯¸ êµ¬ë…ëœ íŠ¸ë™ì„ subscribedTracksRefì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
    // ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ê¸° ì „ì— ì´ë¯¸ êµ¬ë…ëœ íŠ¸ë™ì„ ìˆ˜ì§‘
    const collectExistingSubscribedTracks = () => {
      room.remoteParticipants.forEach((participant) => {
        participant.trackPublications.forEach((publication) => {
          if (
            publication instanceof RemoteTrackPublication &&
            publication.track &&
            shouldSubscribeSource(publication.source)
          ) {
            // ğŸ”§ `::` êµ¬ë¶„ì ì‚¬ìš© (identityì— í•˜ì´í”ˆì´ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
            const key = `${participant.identity}::${publication.source}`
            if (!subscribedTracksRef.current.has(key)) {
              subscribedTracksRef.current.set(key, {
                track: publication.track,
                publication,
                source: publication.source,
              })
              if (IS_DEV) {
                console.log("[LiveKitMediaContext] ğŸ” Found existing subscribed track", {
                  participant: participant.identity,
                  source: publication.source,
                  hasMediaStreamTrack: !!publication.track.mediaStreamTrack,
                })
              }
            }
          }
        })
      })
    }

    // ğŸ”‘ êµ¬ë… ì‹œë„ í•¨ìˆ˜ - isSubscribed=trueì´ì§€ë§Œ track=nullì¸ ê²½ìš°ë„ ì²˜ë¦¬
    const subscribeParticipantTracks = (participant: RemoteParticipant) => {
      participant.trackPublications.forEach((publication) => {
        if (
          publication instanceof RemoteTrackPublication &&
          shouldSubscribeSource(publication.source)
        ) {
          // ğŸ”§ ì¼€ì´ìŠ¤ 1: ì•„ì§ êµ¬ë…ë˜ì§€ ì•Šì€ ê²½ìš°
          if (!publication.isSubscribed) {
            publication.setSubscribed(true)
            if (IS_DEV) {
              console.log("[LiveKitMediaContext] ğŸ“¡ Subscribing remote track", {
                participant: participant.identity,
                source: publication.source,
                trackSid: publication.trackSid,
              })
            }
          }
          // ğŸ”§ ì¼€ì´ìŠ¤ 2: êµ¬ë…ëì§€ë§Œ trackì´ ì•„ì§ ì—†ëŠ” ê²½ìš° (ë ˆì´ìŠ¤ ì»¨ë””ì…˜)
          // â†’ ê°•ì œ ì¬êµ¬ë… ì‹œë„
          else if (publication.isSubscribed && !publication.track) {
            if (IS_DEV) {
              console.log("[LiveKitMediaContext] âš ï¸ Subscribed but no track - forcing re-subscribe", {
                participant: participant.identity,
                source: publication.source,
                trackSid: publication.trackSid,
              })
            }
            // êµ¬ë… í•´ì œ í›„ ì¬êµ¬ë…
            publication.setSubscribed(false)
            setTimeout(() => {
              publication.setSubscribed(true)
            }, 50)
          }
          // ğŸ”§ ì¼€ì´ìŠ¤ 3: ì´ë¯¸ êµ¬ë…ë˜ê³  íŠ¸ë™ë„ ìˆëŠ” ê²½ìš° â†’ subscribedTracksRefì— ì¶”ê°€
          else if (publication.isSubscribed && publication.track) {
            const key = `${participant.identity}::${publication.source}`
            if (!subscribedTracksRef.current.has(key)) {
              subscribedTracksRef.current.set(key, {
                track: publication.track,
                publication,
                source: publication.source,
              })
              if (IS_DEV) {
                console.log("[LiveKitMediaContext] ğŸ” Found subscribed track during subscribe check", {
                  participant: participant.identity,
                  source: publication.source,
                  hasMediaStreamTrack: !!publication.track.mediaStreamTrack,
                })
              }
            }
          }
        }
      })
    }

    // ğŸ”‘ ì¤‘ìš”: ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡ ì „ì— ì´ë¯¸ êµ¬ë…ëœ íŠ¸ë™ ìˆ˜ì§‘
    collectExistingSubscribedTracks()

    // ğŸ”§ í˜„ì¬ ì›ê²© ì°¸ê°€ìë“¤ì˜ íŠ¸ë™ êµ¬ë… ì‹œë„ (ì•„ì§ êµ¬ë…ë˜ì§€ ì•Šì€ íŠ¸ë™)
    room.remoteParticipants.forEach((participant) => subscribeParticipantTracks(participant))

    const handleParticipantConnected = (participant: RemoteParticipant) => {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] ğŸ‘¤ Participant connected:", participant.identity)
      }
      // ì°¸ê°€ì ì—°ê²° ì‹œ ì•½ê°„ì˜ ì§€ì—° í›„ êµ¬ë… ì‹œë„ (íŠ¸ë™ publish ëŒ€ê¸°)
      setTimeout(() => subscribeParticipantTracks(participant), 100)
    }

    const handleTrackPublished = (
      publication: TrackPublication,
      participant: Participant
    ) => {
      if (
        participant instanceof RemoteParticipant &&
        publication instanceof RemoteTrackPublication &&
        shouldSubscribeSource(publication.source)
      ) {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] ğŸ“¢ Track published:", {
            participant: participant.identity,
            source: publication.source,
            isSubscribed: publication.isSubscribed,
            hasTrack: !!publication.track,
          })
        }
        // ğŸ”‘ ì¦‰ì‹œ êµ¬ë… ì‹œë„
        if (!publication.isSubscribed) {
          publication.setSubscribed(true)
        }

        // ğŸ”‘ í•µì‹¬ ê°œì„ : íŠ¸ë™ì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ í´ë§í•˜ê³  ì¤€ë¹„ë˜ë©´ ì €ì¥
        const waitForTrack = (attempts: number = 0) => {
          const track = publication.track
          if (track && track.mediaStreamTrack && track.mediaStreamTrack.readyState !== "ended") {
            // íŠ¸ë™ì´ ì¤€ë¹„ë¨ - subscribedTracksRefì— ì €ì¥
            const key = `${participant.identity}::${publication.source}`
            subscribedTracksRef.current.set(key, {
              track: track as RemoteTrack,
              publication,
              source: publication.source,
            })
            if (IS_DEV) {
              console.log("[LiveKitMediaContext] ğŸ¯ Track ready after polling:", {
                participant: participant.identity,
                source: publication.source,
                attempts,
                hasMediaStreamTrack: !!track.mediaStreamTrack,
              })
            }
            setTrackUpdateTrigger((prev) => prev + 1)
          } else if (attempts < 30) {
            // ìµœëŒ€ 30ë²ˆ ì‹œë„ (3ì´ˆ) - 100ms ê°„ê²©
            setTimeout(() => waitForTrack(attempts + 1), 100)
          } else {
            if (IS_DEV) {
              console.warn("[LiveKitMediaContext] âš ï¸ Track not ready after polling:", {
                participant: participant.identity,
                source: publication.source,
                isSubscribed: publication.isSubscribed,
                hasTrack: !!publication.track,
              })
            }
          }
        }

        // í´ë§ ì‹œì‘
        waitForTrack()

        // ìƒíƒœ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
        setTrackUpdateTrigger((prev) => prev + 1)
      }
    }

    // ğŸ”‘ í•µì‹¬ ê°œì„ : TrackSubscribedì—ì„œ íŠ¸ë™ì„ ì§ì ‘ ì €ì¥
    const handleTrackSubscribed = (
      track: RemoteTrack,
      publication: RemoteTrackPublication,
      participant: RemoteParticipant
    ) => {
      // ğŸ”§ `::` êµ¬ë¶„ì ì‚¬ìš© (identityì— í•˜ì´í”ˆì´ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
      const key = `${participant.identity}::${publication.source}`
      subscribedTracksRef.current.set(key, {
        track,
        publication,
        source: publication.source,
      })

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] âœ… Track subscribed - stored in ref", {
          participant: participant.identity,
          source: publication.source,
          hasMediaStreamTrack: !!track.mediaStreamTrack,
          refSize: subscribedTracksRef.current.size,
        })
      }

      // React ìƒíƒœ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
      setTrackUpdateTrigger((prev) => prev + 1)
    }

    // ğŸ”§ TrackUnsubscribed: refì—ì„œ ì œê±°
    const handleTrackUnsubscribed = (
      track: RemoteTrack,
      publication: RemoteTrackPublication,
      participant: RemoteParticipant
    ) => {
      // ğŸ”§ `::` êµ¬ë¶„ì ì‚¬ìš© (identityì— í•˜ì´í”ˆì´ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
      const key = `${participant.identity}::${publication.source}`
      subscribedTracksRef.current.delete(key)

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] âŒ Track unsubscribed - removed from ref", {
          participant: participant.identity,
          source: publication.source,
        })
      }

      setTrackUpdateTrigger((prev) => prev + 1)
    }

    // ğŸ”§ TrackMuted/Unmuted ì´ë²¤íŠ¸ë„ ì²˜ë¦¬
    const handleTrackMuted = (publication: TrackPublication, participant: Participant) => {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] ğŸ”‡ Track muted:", {
          participant: participant.identity,
          source: publication.source,
        })
      }
      setTrackUpdateTrigger((prev) => prev + 1)
    }

    const handleTrackUnmuted = (publication: TrackPublication, participant: Participant) => {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] ğŸ”Š Track unmuted:", {
          participant: participant.identity,
          source: publication.source,
        })
      }
      setTrackUpdateTrigger((prev) => prev + 1)
    }

    room.on(RoomEvent.ParticipantConnected, handleParticipantConnected)
    room.on(RoomEvent.TrackPublished, handleTrackPublished)
    room.on(RoomEvent.TrackSubscribed, handleTrackSubscribed)
    room.on(RoomEvent.TrackUnsubscribed, handleTrackUnsubscribed)
    room.on(RoomEvent.TrackMuted, handleTrackMuted)
    room.on(RoomEvent.TrackUnmuted, handleTrackUnmuted)

    // ğŸ”§ Late Joiner ëŒ€ì‘: ë‹¤ë‹¨ê³„ ì¬ì‹œë„ + íŠ¸ë™ ìˆ˜ì§‘ (ë” ê¸´ ê°„ê²© ì¶”ê°€)
    const retryTimeouts = [100, 300, 600, 1000, 2000, 3000, 5000].map((delay) =>
      setTimeout(() => {
        if (IS_DEV) {
          console.log(`[LiveKitMediaContext] ğŸ”„ Retry after ${delay}ms - collecting tracks and subscribing`, {
            remoteParticipantsCount: room.remoteParticipants.size,
            subscribedTracksRefSize: subscribedTracksRef.current.size,
          })
        }
        // ğŸ”‘ ì´ë¯¸ êµ¬ë…ëœ íŠ¸ë™ ìˆ˜ì§‘ (ì´ë²¤íŠ¸ë¥¼ ë†“ì³¤ì„ ìˆ˜ ìˆìŒ)
        collectExistingSubscribedTracks()
        // ì•„ì§ êµ¬ë…ë˜ì§€ ì•Šì€ íŠ¸ë™ ë˜ëŠ” trackì´ nullì¸ ê²½ìš° êµ¬ë… ì‹œë„
        room.remoteParticipants.forEach((participant) => subscribeParticipantTracks(participant))
        setTrackUpdateTrigger((prev) => prev + 1)
      }, delay)
    )

    return () => {
      retryTimeouts.forEach(clearTimeout)
      room.off(RoomEvent.ParticipantConnected, handleParticipantConnected)
      room.off(RoomEvent.TrackPublished, handleTrackPublished)
      room.off(RoomEvent.TrackSubscribed, handleTrackSubscribed)
      room.off(RoomEvent.TrackUnsubscribed, handleTrackUnsubscribed)
      room.off(RoomEvent.TrackMuted, handleTrackMuted)
      room.off(RoomEvent.TrackUnmuted, handleTrackUnmuted)
    }
  }, [room, isConnected])  // ğŸ”§ participants ì œê±° - ì´ë²¤íŠ¸ ë“œë¦¬ë¸ìœ¼ë¡œ ì²˜ë¦¬

  // ğŸ”§ iOS Safari ì˜¤ë””ì˜¤ unlock ìƒíƒœ ì¶”ì 
  const audioUnlockedRef = useRef(false)
  // ğŸ“Œ iOS Safari ë¯¸ë””ì–´ ì„¸ì…˜ í™œì„±í™” ìƒíƒœ (getUserMedia í˜¸ì¶œ í•„ìš”)
  const mediaSessionActivatedRef = useRef(false)

  // ğŸ“Œ iOS/iPadOS Safari ê°ì§€ (getUserMedia í•„ìš”í•œ í™˜ê²½)
  const isIOSSafari = useMemo(() => {
    if (typeof window === "undefined" || typeof navigator === "undefined") return false
    const ua = navigator.userAgent
    const isIOS = /iPad|iPhone|iPod/.test(ua) ||
      (navigator.platform === "MacIntel" && navigator.maxTouchPoints > 1)
    // iOSì˜ ëª¨ë“  ë¸Œë¼ìš°ì €ëŠ” WebKit ê¸°ë°˜ì´ë¯€ë¡œ Safariì™€ ë™ì¼í•œ ì œí•œ
    return isIOS
  }, [])

  // ì—°ê²° ì‹œ ìë™ìœ¼ë¡œ ì˜¤ë””ì˜¤ ì‹œì‘ (ë¸Œë¼ìš°ì € autoplay ì •ì±… ëŒ€ì‘)
  // ğŸ“Œ iOS Safari: ì‚¬ìš©ì ì œìŠ¤ì²˜ ì—†ì´ ì˜¤ë””ì˜¤ ì¬ìƒ ë¶ˆê°€ â†’ ì²« í„°ì¹˜ê¹Œì§€ ë°˜ë³µ ì‹œë„
  // ğŸ“Œ í•µì‹¬ ê°œì„ : room.startAudio()ë§Œìœ¼ë¡œëŠ” ê°œë³„ <audio> ì—˜ë¦¬ë¨¼íŠ¸ ì¬ìƒì´ ì•ˆ ë¨
  //    â†’ ëª¨ë“  <audio> ì—˜ë¦¬ë¨¼íŠ¸ì˜ play()ë¥¼ ì§ì ‘ í˜¸ì¶œí•´ì•¼ í•¨
  // ğŸ“Œ iOS Safari íŠ¹ìˆ˜ ì²˜ë¦¬: getUserMedia í˜¸ì¶œí•˜ì—¬ ë¯¸ë””ì–´ ì„¸ì…˜ í™œì„±í™” í•„ìš”
  useEffect(() => {
    if (!room || !isConnected) return

    // ğŸ”§ ëª¨ë“  <audio> ì—˜ë¦¬ë¨¼íŠ¸ ì¬ìƒ ì‹œë„ (iOS Safariìš©)
    const playAllAudioElements = () => {
      const audioElements = document.querySelectorAll("audio")
      audioElements.forEach((audio) => {
        if (audio.paused && audio.srcObject) {
          audio.play().catch(() => {
            // ê°œë³„ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ (ë‹¤ìŒ ì‹œë„ì—ì„œ ì„±ê³µí•  ìˆ˜ ìˆìŒ)
          })
        }
      })
      if (IS_DEV && audioElements.length > 0) {
        console.log(`[LiveKitMediaContext] ğŸ”Š Attempted to play ${audioElements.length} audio elements`)
      }
    }

    // ğŸ“Œ iOS Safari ì „ìš©: ë¯¸ë””ì–´ ì„¸ì…˜ í™œì„±í™” (getUserMedia í˜¸ì¶œ)
    // iOS Safariì—ì„œëŠ” getUserMediaë¥¼ í˜¸ì¶œí•´ì•¼ WebRTC ì˜¤ë””ì˜¤ ì¶œë ¥ì´ í™œì„±í™”ë¨
    // ë§ˆì´í¬ë¥¼ ì§§ê²Œ ì¼°ë‹¤ê°€ ë°”ë¡œ ë” (silent activation)
    const activateIOSMediaSession = async (): Promise<boolean> => {
      if (mediaSessionActivatedRef.current) return true
      if (!isIOSSafari) {
        mediaSessionActivatedRef.current = true
        return true
      }

      try {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] ğŸ iOS: Activating media session via getUserMedia...")
        }

        // ì˜¤ë””ì˜¤ë§Œ ìš”ì²­ (ì¹´ë©”ë¼ëŠ” ë¶ˆí•„ìš”)
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })

        // ì¦‰ì‹œ íŠ¸ë™ ì¤‘ì§€ (ë§ˆì´í¬ ì‚¬ìš© ì•ˆ í•¨)
        stream.getTracks().forEach((track) => {
          track.stop()
        })

        mediaSessionActivatedRef.current = true
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] ğŸ iOS: Media session activated successfully")
        }
        return true
      } catch (error) {
        // ê¶Œí•œ ê±°ë¶€ ì‹œì—ë„ ê³„ì† ì§„í–‰ (ì‚¬ìš©ìê°€ ë§ˆì´í¬ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¼¤ ìˆ˜ ìˆìŒ)
        if (IS_DEV) {
          console.warn("[LiveKitMediaContext] ğŸ iOS: Media session activation failed:", error)
        }
        return false
      }
    }

    // ğŸ”§ ì˜¤ë””ì˜¤ unlock ì‹œë„ í•¨ìˆ˜ (ê°•í™”ëœ ë²„ì „)
    const tryUnlockAudio = async () => {
      if (audioUnlockedRef.current && mediaSessionActivatedRef.current) return true

      try {
        // 1. LiveKit AudioContext resume
        await room.startAudio()

        // 2. ğŸ“Œ í•µì‹¬: ëª¨ë“  <audio> ì—˜ë¦¬ë¨¼íŠ¸ ì§ì ‘ ì¬ìƒ ì‹œë„
        playAllAudioElements()

        audioUnlockedRef.current = true
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] âœ… Audio context unlocked + audio elements played")
        }
        return true
      } catch {
        // ì‚¬ìš©ì ì¸í„°ë™ì…˜ ì—†ì´ëŠ” ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ - ì •ìƒì ì¸ ë™ì‘
        return false
      }
    }

    // ì´ˆê¸° ì‹œë„
    tryUnlockAudio()

    // ğŸ”§ ì‚¬ìš©ì ì¸í„°ë™ì…˜ ì‹œ ì˜¤ë””ì˜¤ unlock ì‹œë„ (ì„±ê³µí•  ë•Œê¹Œì§€ ë°˜ë³µ)
    // ğŸ“Œ iOS Safari: getUserMediaë¥¼ í˜¸ì¶œí•˜ì—¬ ë¯¸ë””ì–´ ì„¸ì…˜ í™œì„±í™”
    const handleUserInteraction = async () => {
      // ğŸ“Œ iOS Safari: ë¯¸ë””ì–´ ì„¸ì…˜ í™œì„±í™” (ì²« ì¸í„°ë™ì…˜ì—ì„œë§Œ)
      if (isIOSSafari && !mediaSessionActivatedRef.current) {
        await activateIOSMediaSession()
      }

      // ì˜¤ë””ì˜¤ unlock ì‹œë„
      await tryUnlockAudio()

      // ğŸ“Œ ì¶”ê°€ ì•ˆì „ì¥ì¹˜: unlock í›„ì—ë„ í•œ ë²ˆ ë” ëª¨ë“  audio ì¬ìƒ ì‹œë„
      playAllAudioElements()
    }

    // ğŸ“Œ once: true ì œê±° - ì„±ê³µí•  ë•Œê¹Œì§€ ê³„ì† ì‹œë„
    // ğŸ“Œ passive: true ì¶”ê°€ - iOSì—ì„œ ìŠ¤í¬ë¡¤ ì„±ëŠ¥ ìµœì í™”
    document.addEventListener("click", handleUserInteraction)
    document.addEventListener("touchstart", handleUserInteraction, { passive: true })
    document.addEventListener("touchend", handleUserInteraction, { passive: true })
    document.addEventListener("keydown", handleUserInteraction)

    return () => {
      document.removeEventListener("click", handleUserInteraction)
      document.removeEventListener("touchstart", handleUserInteraction)
      document.removeEventListener("touchend", handleUserInteraction)
      document.removeEventListener("keydown", handleUserInteraction)
    }
  }, [room, isConnected, isIOSSafari])

  // ğŸ”‘ í•µì‹¬ ê°œì„ : useTracks ê²°ê³¼ì—ì„œ ì§ì ‘ subscribedTracksRefë¡œ ë™ê¸°í™”
  // TrackSubscribed ì´ë²¤íŠ¸ë¥¼ ë†“ì¹˜ëŠ” ê²½ìš°ë¥¼ ë³´ì™„
  useEffect(() => {
    if (!isConnected) return

    let syncCount = 0
    tracks.forEach((trackRef) => {
      const participant = trackRef.participant
      // ë¡œì»¬ ì°¸ê°€ìëŠ” ì œì™¸
      if (participant.isLocal) return

      const publication = trackRef.publication
      const track = publication?.track

      if (track && track.mediaStreamTrack && track.mediaStreamTrack.readyState !== "ended") {
        const key = `${participant.identity}::${trackRef.source}`

        // ì•„ì§ refì— ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
        if (!subscribedTracksRef.current.has(key)) {
          subscribedTracksRef.current.set(key, {
            track: track as RemoteTrack,
            publication: publication as RemoteTrackPublication,
            source: trackRef.source,
          })
          syncCount++

          if (IS_DEV) {
            console.log("[LiveKitMediaContext] ğŸ”„ Synced track from useTracks to ref:", {
              participant: participant.identity,
              source: trackRef.source,
              hasMediaStreamTrack: !!track.mediaStreamTrack,
            })
          }
        }
      }
    })

    // ìƒˆë¡œ ë™ê¸°í™”ëœ íŠ¸ë™ì´ ìˆìœ¼ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
    if (syncCount > 0) {
      if (IS_DEV) {
        console.log(`[LiveKitMediaContext] ğŸ”„ Synced ${syncCount} tracks from useTracks`)
      }
      setTrackUpdateTrigger((prev) => prev + 1)
    }
  }, [tracks, isConnected])

  // ğŸ”‘ participantTracks ë¹Œë“œ: 3ë‹¨ê³„ íŠ¸ë™ ìˆ˜ì§‘ ì „ëµ (ìš°ì„ ìˆœìœ„ ì¬ì •ë ¬)
  // 1ë‹¨ê³„: useTracks ê²°ê³¼ (React í†µí•© - late joinerì—ê²Œ ê°€ì¥ ì•ˆì •ì )
  // 2ë‹¨ê³„: subscribedTracksRef (ì´ë²¤íŠ¸ ê¸°ë°˜ - ì¶”ê°€ íŠ¸ë™ ë°±ì—…)
  // 3ë‹¨ê³„: room.remoteParticipantsì—ì„œ ì§ì ‘ ìˆ˜ì§‘ (Fallback)
  const participantTracks = useMemo(() => {
    const map = new Map<string, ParticipantTrack>()

    if (!isConnected || participants.length === 0) {
      return map
    }

    // ğŸ”‘ revision ê³„ì‚°: trackUpdateTriggerë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ì°¸ê°€ìë³„ revision ì„¤ì •
    // ì´ë¥¼ í†µí•´ Reactê°€ íŠ¸ë™ ë³€ê²½ì„ ê°ì§€í•  ìˆ˜ ìˆìŒ
    const currentRevision = trackUpdateTrigger

    // ê¸°ë³¸ ì—”íŠ¸ë¦¬ ìƒì„±
    participants.forEach((participant) => {
      map.set(participant.identity, {
        participantId: participant.identity,
        participantName: participant.name || participant.identity,
        isSpeaking: participant.isSpeaking,
        isVideoMuted: true,
        isAudioMuted: true,
        isScreenMuted: true,
        revision: currentRevision, // ğŸ”‘ revision ì¶”ê°€
      })
    })

    // 1ï¸âƒ£ ìµœìš°ì„ : useTracks ê²°ê³¼ì—ì„œ íŠ¸ë™ ê°€ì ¸ì˜¤ê¸°
    // React í†µí•©ëœ í›…ì´ë¯€ë¡œ late joinerì—ê²Œ ê°€ì¥ ì•ˆì •ì 
    tracks.forEach((trackRef) => {
      const identity = trackRef.participant.identity
      const entry = map.get(identity)
      if (!entry) return

      const publication = trackRef.publication
      const mediaTrack = publication?.track?.mediaStreamTrack
      // ğŸ”‘ í•µì‹¬: isMutedê°€ ëª…ì‹œì ìœ¼ë¡œ trueì¸ ê²½ìš°ì—ë§Œ mutedë¡œ ì²˜ë¦¬
      // undefinedë‚˜ falseëŠ” ëª¨ë‘ unmutedë¡œ ì²˜ë¦¬ (íŠ¸ë™ì´ ìˆìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±)
      const isMuted = publication?.isMuted === true

      switch (trackRef.source) {
        case Track.Source.Camera:
          if (mediaTrack && mediaTrack.readyState !== "ended") {
            entry.videoTrack = mediaTrack
            entry.isVideoMuted = isMuted
          }
          break
        case Track.Source.Microphone:
          if (mediaTrack && mediaTrack.readyState !== "ended") {
            entry.audioTrack = mediaTrack
            entry.isAudioMuted = isMuted
          }
          break
        case Track.Source.ScreenShare:
          if (mediaTrack && mediaTrack.readyState !== "ended") {
            entry.screenTrack = mediaTrack
            entry.isScreenMuted = isMuted
          }
          break
      }
    })

    // 2ï¸âƒ£ ë°±ì—…: subscribedTracksRefì—ì„œ ì¶”ê°€ íŠ¸ë™ ê°€ì ¸ì˜¤ê¸°
    // useTracksì—ì„œ ëª» ì¡ì€ íŠ¸ë™ì´ ìˆì„ ìˆ˜ ìˆìŒ
    subscribedTracksRef.current.forEach((storedInfo, key) => {
      // ğŸ”§ `::` êµ¬ë¶„ìë¡œ íŒŒì‹± (identityì— í•˜ì´í”ˆì´ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
      const [identity] = key.split("::")
      const entry = map.get(identity)
      if (!entry) return

      const mediaTrack = storedInfo.track.mediaStreamTrack
      if (!mediaTrack || mediaTrack.readyState === "ended") return

      // ğŸ”‘ í•µì‹¬: useTracksì—ì„œ ì´ë¯¸ íŠ¸ë™ì„ ì„¤ì •í–ˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
      // subscribedTracksRefëŠ” ë°±ì—… ì—­í• ë§Œ
      const isMuted = storedInfo.publication.isMuted === true

      switch (storedInfo.source) {
        case Track.Source.Camera:
          if (!entry.videoTrack) {
            entry.videoTrack = mediaTrack
            entry.isVideoMuted = isMuted
          }
          break
        case Track.Source.Microphone:
          if (!entry.audioTrack) {
            entry.audioTrack = mediaTrack
            entry.isAudioMuted = isMuted
          }
          break
        case Track.Source.ScreenShare:
          if (!entry.screenTrack) {
            entry.screenTrack = mediaTrack
            entry.isScreenMuted = isMuted
          }
          break
      }
    })

    // 3ï¸âƒ£ Fallback: room.remoteParticipantsì—ì„œ ì§ì ‘ íŠ¸ë™ í™•ì¸
    if (room) {
      room.remoteParticipants.forEach((remoteParticipant) => {
        const entry = map.get(remoteParticipant.identity)
        if (!entry) return

        remoteParticipant.trackPublications.forEach((publication) => {
          const track = publication.track
          // ğŸ”‘ í•µì‹¬ ìˆ˜ì •: isMutedê°€ ëª…ì‹œì ìœ¼ë¡œ trueì¸ ê²½ìš°ì—ë§Œ mutedë¡œ ì²˜ë¦¬
          const isMuted = publication.isMuted === true

          switch (publication.source) {
            case Track.Source.Camera:
              if (track?.mediaStreamTrack && track.mediaStreamTrack.readyState !== "ended") {
                if (!entry.videoTrack) {
                  entry.videoTrack = track.mediaStreamTrack
                  if (IS_DEV) {
                    console.log("[LiveKitMediaContext] ğŸ”§ Fallback: Got video track from room", {
                      participant: remoteParticipant.identity,
                      isMuted: publication.isMuted,
                    })
                  }
                }
                // ğŸ”‘ íŠ¸ë™ì´ ìˆì„ ë•Œë§Œ isMuted ìƒíƒœ ì—…ë°ì´íŠ¸
                entry.isVideoMuted = isMuted
              }
              break
            case Track.Source.Microphone:
              if (track?.mediaStreamTrack && track.mediaStreamTrack.readyState !== "ended") {
                if (!entry.audioTrack) {
                  entry.audioTrack = track.mediaStreamTrack
                }
                entry.isAudioMuted = isMuted
              }
              break
            case Track.Source.ScreenShare:
              if (track?.mediaStreamTrack && track.mediaStreamTrack.readyState !== "ended") {
                if (!entry.screenTrack) {
                  entry.screenTrack = track.mediaStreamTrack
                }
                entry.isScreenMuted = isMuted
              }
              break
          }
        })
      })
    }

    if (IS_DEV) {
      console.log("[LiveKitMediaContext] ğŸ“Š participantTracks built:", {
        participantCount: map.size,
        subscribedTracksRefSize: subscribedTracksRef.current.size,
        useTracksCount: tracks.length,
        trackUpdateTrigger,
      })
      // useTracks ê²°ê³¼ ìƒì„¸ ë¡œê·¸
      console.log("[LiveKitMediaContext] ğŸ” useTracks details:")
      tracks.forEach((trackRef, idx) => {
        console.log(`  [${idx}] ${trackRef.participant.identity} (${trackRef.source}):`, {
          isLocal: trackRef.participant.isLocal,
          hasPublication: !!trackRef.publication,
          isSubscribed: trackRef.publication?.isSubscribed,
          hasTrack: !!trackRef.publication?.track,
          hasMediaStreamTrack: !!trackRef.publication?.track?.mediaStreamTrack,
          isMuted: trackRef.publication?.isMuted,
        })
      })
      map.forEach((track, identity) => {
        console.log(`  - ${identity}:`, {
          hasVideo: !!track.videoTrack,
          hasAudio: !!track.audioTrack,
          hasScreen: !!track.screenTrack,
          isVideoMuted: track.isVideoMuted,
          isAudioMuted: track.isAudioMuted,
        })
      })
    }

    return map
  }, [participants, tracks, isConnected, trackUpdateTrigger, room])

  // ğŸ”‘ íŠ¸ë™ ì¤€ë¹„ ëŒ€ê¸° ëª¨ë‹ˆí„°ë§ - ë ˆì´ìŠ¤ ì»¨ë””ì…˜ í•´ê²°
  // useTracksì—ì„œ íŠ¸ë™ì„ ê°ì§€í–ˆì§€ë§Œ mediaStreamTrackì´ ì•„ì§ ì¤€ë¹„ ì•ˆ ëœ ê²½ìš°
  // ì£¼ê¸°ì ìœ¼ë¡œ ë¦¬ë Œë”ë§ì„ íŠ¸ë¦¬ê±°í•˜ì—¬ íŠ¸ë™ ì¤€ë¹„ ì™„ë£Œ ì‹œì ì„ í¬ì°©
  useEffect(() => {
    // ì•„ì§ mediaStreamTrackì´ ì¤€ë¹„ ì•ˆ ëœ ì›ê²© íŠ¸ë™ ì°¾ê¸°
    const pendingTracks = tracks.filter((trackRef) => {
      // ë¡œì»¬ ì°¸ê°€ìëŠ” ë¬´ì‹œ
      if (trackRef.participant.isLocal) return false
      const pub = trackRef.publication
      // publicationì´ ìˆê³ , êµ¬ë…ëê±°ë‚˜ íŠ¸ë™ì´ ìˆëŠ”ë° mediaStreamTrackì´ ì—†ëŠ” ê²½ìš°
      return (
        pub &&
        (pub.isSubscribed || pub.track) &&
        !pub.track?.mediaStreamTrack
      )
    })

    if (
      pendingTracks.length > 0 &&
      trackReadyRetryCountRef.current < MAX_TRACK_READY_RETRIES
    ) {
      trackReadyRetryCountRef.current++
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] â³ Waiting for tracks to be ready:", {
          pending: pendingTracks.length,
          retry: trackReadyRetryCountRef.current,
          tracks: pendingTracks.map((t) => ({
            participant: t.participant.identity,
            source: t.source,
            hasTrack: !!t.publication?.track,
            hasMediaStreamTrack: !!t.publication?.track?.mediaStreamTrack,
          })),
        })
      }
      // 100ms í›„ ë¦¬ë Œë”ë§ íŠ¸ë¦¬ê±°
      const timer = setTimeout(() => {
        setTrackUpdateTrigger((prev) => prev + 1)
      }, 100)
      return () => clearTimeout(timer)
    } else if (pendingTracks.length === 0) {
      // ëª¨ë“  íŠ¸ë™ ì¤€ë¹„ ì™„ë£Œ - ì¹´ìš´í„° ë¦¬ì…‹
      trackReadyRetryCountRef.current = 0
    }
  }, [tracks, trackUpdateTrigger])

  // Media state - useLocalParticipantì˜ reactive ê°’ ì§ì ‘ ì‚¬ìš©
  const mediaState: MediaState = useMemo(() => ({
    isCameraEnabled: isCameraEnabled ?? false,
    isMicrophoneEnabled: isMicrophoneEnabled ?? false,
    isScreenShareEnabled: isScreenShareEnabled ?? false,
  }), [isCameraEnabled, isMicrophoneEnabled, isScreenShareEnabled])

  // Error parser
  const parseMediaError = useCallback((error: unknown): MediaError => {
    const errorMessage = error instanceof Error ? error.message : String(error)

    if (
      errorMessage.includes("Permission denied") ||
      errorMessage.includes("NotAllowedError")
    ) {
      return {
        type: "permission_denied",
        message: "ì¹´ë©”ë¼/ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.",
      }
    }
    if (
      errorMessage.includes("NotFoundError") ||
      errorMessage.includes("not found")
    ) {
      return { type: "not_found", message: "ì¹´ë©”ë¼/ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." }
    }
    return { type: "unknown", message: errorMessage }
  }, [])

  // ğŸ”§ ëª¨ë“  <audio> ì—˜ë¦¬ë¨¼íŠ¸ ì¬ìƒ ì‹œë„ (iOS Safariìš©) - í† ê¸€ í•¨ìˆ˜ì—ì„œ ì¬ì‚¬ìš©
  const playAllAudioElements = useCallback(() => {
    const audioElements = document.querySelectorAll("audio")
    audioElements.forEach((audio) => {
      if (audio.paused && audio.srcObject) {
        audio.play().catch(() => {
          // ê°œë³„ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
        })
      }
    })
    if (IS_DEV && audioElements.length > 0) {
      console.log(`[LiveKitMediaContext] ğŸ”Š Toggle triggered: played ${audioElements.length} audio elements`)
    }
  }, [])

  // Toggle camera
  // ğŸ“Œ iOS Safari: setCameraEnabled í›„ í„°ì¹˜ ì´ë²¤íŠ¸ê°€ ë¨¹í†µë˜ëŠ” ë¬¸ì œ ëŒ€ì‘
  const toggleCamera = useCallback(async (): Promise<boolean> => {
    if (!localParticipant) {
      setMediaError({
        type: "not_connected",
        message: "LiveKitì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      })
      return false
    }

    try {
      setMediaError(null)

      // ğŸ”§ ì˜¤ë””ì˜¤ unlock ì‹œë„ (ì¹´ë©”ë¼ í† ê¸€ë„ ì‚¬ìš©ì ì œìŠ¤ì²˜ì´ë¯€ë¡œ ì´ ì‹œì ì— unlock ê°€ëŠ¥)
      if (room) {
        await room.startAudio().catch(() => {})
        audioUnlockedRef.current = true
        // ğŸ“Œ í•µì‹¬: ëª¨ë“  <audio> ì—˜ë¦¬ë¨¼íŠ¸ ì§ì ‘ ì¬ìƒ ì‹œë„
        playAllAudioElements()
      }

      const newState = !localParticipant.isCameraEnabled
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Toggle camera:", newState ? "ON" : "OFF")
      }

      await localParticipant.setCameraEnabled(newState)

      // ğŸ“Œ iOS Safari í„°ì¹˜ ì´ë²¤íŠ¸ ë³µêµ¬
      if (typeof window !== "undefined" && /iPad|iPhone|iPod/.test(navigator.userAgent)) {
        requestAnimationFrame(() => {
          const activeEl = document.activeElement as HTMLElement | null
          if (activeEl && typeof activeEl.blur === "function") {
            activeEl.blur()
          }
          if (IS_DEV) {
            console.log("[LiveKitMediaContext] iOS touch event recovery executed")
          }
        })
      }

      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] Camera toggle error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [localParticipant, room, parseMediaError, playAllAudioElements])

  // Toggle microphone
  // ğŸ“Œ iOS Safari: setMicrophoneEnabled í›„ í„°ì¹˜ ì´ë²¤íŠ¸ê°€ ë¨¹í†µë˜ëŠ” ë¬¸ì œ ëŒ€ì‘
  const toggleMicrophone = useCallback(async (): Promise<boolean> => {
    if (!localParticipant) {
      setMediaError({
        type: "not_connected",
        message: "LiveKitì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      })
      return false
    }

    try {
      setMediaError(null)

      // ğŸ”§ ì˜¤ë””ì˜¤ unlock ì‹œë„ (ë§ˆì´í¬ í† ê¸€ì´ ì‚¬ìš©ì ì œìŠ¤ì²˜ì´ë¯€ë¡œ ì´ ì‹œì ì— unlock ê°€ëŠ¥)
      if (room) {
        await room.startAudio().catch(() => {})
        audioUnlockedRef.current = true
        // ğŸ“Œ í•µì‹¬: ëª¨ë“  <audio> ì—˜ë¦¬ë¨¼íŠ¸ ì§ì ‘ ì¬ìƒ ì‹œë„
        playAllAudioElements()
      }

      const newState = !localParticipant.isMicrophoneEnabled
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Toggle microphone:", newState ? "ON" : "OFF")
      }

      await localParticipant.setMicrophoneEnabled(newState)

      // ğŸ“Œ iOS Safari í„°ì¹˜ ì´ë²¤íŠ¸ ë³µêµ¬
      // getUserMedia ê¶Œí•œ ë‹¤ì´ì–¼ë¡œê·¸ í›„ í„°ì¹˜ ì´ë²¤íŠ¸ê°€ ë¨¹í†µë˜ëŠ” ë¬¸ì œ ëŒ€ì‘
      // requestAnimationFrameìœ¼ë¡œ ë‹¤ìŒ í”„ë ˆì„ê¹Œì§€ ëŒ€ê¸° í›„ blur ì²˜ë¦¬
      if (typeof window !== "undefined" && /iPad|iPhone|iPod/.test(navigator.userAgent)) {
        requestAnimationFrame(() => {
          // í˜„ì¬ í¬ì»¤ìŠ¤ëœ ìš”ì†Œê°€ ìˆìœ¼ë©´ blur
          const activeEl = document.activeElement as HTMLElement | null
          if (activeEl && typeof activeEl.blur === "function") {
            activeEl.blur()
          }
          if (IS_DEV) {
            console.log("[LiveKitMediaContext] iOS touch event recovery executed")
          }
        })
      }

      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] Microphone toggle error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [localParticipant, room, parseMediaError, playAllAudioElements])

  // ë¡œì»¬ ì˜¤ë””ì˜¤ íŠ¸ë™ (VADìš©)
  const localAudioTrack = useMemo(() => {
    if (!localParticipant || !isConnected) return null
    const audioTrackRef = tracks.find(
      (t) => t.participant === localParticipant && t.source === Track.Source.Microphone
    )
    return audioTrackRef?.publication?.track?.mediaStreamTrack ?? null
  }, [localParticipant, tracks, isConnected])

  // VAD ê²Œì´íŠ¸ìš©: ë¡œì»¬ ë§ˆì´í¬ ë®¤íŠ¸/ì–¸ë®¤íŠ¸ (íŠ¸ë™ ìœ ì§€í•˜ë©´ì„œ ë°ì´í„°ë§Œ ë®¤íŠ¸)
  const setLocalMicrophoneMuted = useCallback(async (muted: boolean): Promise<boolean> => {
    if (!localParticipant) {
      return false
    }

    try {
      const publication = localParticipant.getTrackPublication(Track.Source.Microphone)
      if (!publication) {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] No microphone publication found for VAD")
        }
        return false
      }

      if (muted) {
        await publication.mute()
      } else {
        await publication.unmute()
      }

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] VAD: Microphone muted:", muted)
      }
      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] setLocalMicrophoneMuted error:", error)
      return false
    }
  }, [localParticipant])

  // ğŸ“Œ ì†ŒìŠ¤ ë ˆë²¨ ì˜¤ë””ì˜¤ ê²Œì´íŠ¸: MediaStreamTrack.enabled ì§ì ‘ ì œì–´
  // publication.mute()ì™€ ë‹¬ë¦¬ WebRTC ì†ŒìŠ¤ ë ˆë²¨ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ì°¨ë‹¨
  // - gated=true: ì˜¤ë””ì˜¤ ì¶œë ¥ ì°¨ë‹¨ (track.enabled=false)
  // - gated=false: ì˜¤ë””ì˜¤ ì¶œë ¥ í—ˆìš© (track.enabled=true)
  const setLocalAudioGated = useCallback((gated: boolean): boolean => {
    if (!localParticipant) {
      return false
    }

    try {
      const publication = localParticipant.getTrackPublication(Track.Source.Microphone)
      if (!publication?.track) {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] setLocalAudioGated: No track found")
        }
        return false
      }

      // MediaStreamTrack ì§ì ‘ ì ‘ê·¼
      const mediaStreamTrack = publication.track.mediaStreamTrack
      if (!mediaStreamTrack) {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] setLocalAudioGated: No mediaStreamTrack")
        }
        return false
      }

      // ì†ŒìŠ¤ ë ˆë²¨ì—ì„œ ì˜¤ë””ì˜¤ enabled/disabled ì œì–´
      // enabled=false: íŠ¸ë™ì€ ìœ ì§€ë˜ì§€ë§Œ ë¬´ìŒ í”„ë ˆì„ ì „ì†¡
      mediaStreamTrack.enabled = !gated

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] setLocalAudioGated:", {
          gated,
          trackEnabled: mediaStreamTrack.enabled,
        })
      }

      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] setLocalAudioGated error:", error)
      return false
    }
  }, [localParticipant])

  // ğŸ“Œ AudioWorklet ì²˜ë¦¬ëœ íŠ¸ë™ìœ¼ë¡œ êµì²´
  // LiveKitì˜ ê¸°ì¡´ ë§ˆì´í¬ íŠ¸ë™ì„ AudioWorkletì—ì„œ ì²˜ë¦¬ëœ íŠ¸ë™ìœ¼ë¡œ êµì²´
  // ğŸ”§ í•µì‹¬ ìˆ˜ì •: RTCRtpSender.replaceTrack()ì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ì‹¤ì œ WebRTC ì „ì†¡ íŠ¸ë™ êµì²´
  const replaceAudioTrackWithProcessed = useCallback(async (processedTrack: MediaStreamTrack): Promise<boolean> => {
    if (!localParticipant || !room) {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] replaceAudioTrackWithProcessed: No local participant or room")
      }
      return false
    }

    try {
      const publication = localParticipant.getTrackPublication(Track.Source.Microphone)
      if (!publication?.track) {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] replaceAudioTrackWithProcessed: No publication track")
        }
        return false
      }

      // ğŸ”§ í•µì‹¬: RTCRtpSenderì—ì„œ ì§ì ‘ íŠ¸ë™ êµì²´ (WebRTC ë ˆë²¨)
      // LocalTrack.replaceTrack()ì€ ë‚´ë¶€ ì°¸ì¡°ë§Œ ë³€ê²½í•˜ê³  ì‹¤ì œ ì „ì†¡ íŠ¸ë™ì€ ë³€ê²½í•˜ì§€ ì•ŠìŒ
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const engine = (room as any).engine
      const sender = engine?.publisher?.pc?.getSenders()?.find(
        (s: RTCRtpSender) => s.track?.kind === "audio"
      )

      if (!sender) {
        console.warn("[LiveKitMediaContext] replaceAudioTrackWithProcessed: No audio sender found")
        return false
      }

      // RTCRtpSender.replaceTrack()ìœ¼ë¡œ ì‹¤ì œ ì „ì†¡ íŠ¸ë™ êµì²´
      await sender.replaceTrack(processedTrack)

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] replaceAudioTrackWithProcessed: Track replaced via RTCRtpSender", {
          newTrackId: processedTrack.id,
          newTrackLabel: processedTrack.label,
          senderTrackId: sender.track?.id,
        })
      }

      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] replaceAudioTrackWithProcessed error:", error)
      return false
    }
  }, [localParticipant, room])

  // ğŸ“Œ ì˜¤ë””ì˜¤ ì˜µì…˜ ë³€ê²½ ì‹œ ë§ˆì´í¬ ì¬ì‹œì‘ (ë™ì  ì ìš©)
  // LiveKitì€ íŠ¸ë™ ìº¡ì²˜ ì‹œì—ë§Œ ì˜µì…˜ì„ ì ìš©í•˜ë¯€ë¡œ, ì„¤ì • ë³€ê²½ ì‹œ ë§ˆì´í¬ë¥¼ ì¬ì‹œì‘í•´ì•¼ í•¨
  const restartMicrophoneWithOptions = useCallback(async (options: AudioCaptureOptionsInput): Promise<boolean> => {
    if (!localParticipant) {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] restartMicrophoneWithOptions: No local participant")
      }
      return false
    }

    // ë§ˆì´í¬ê°€ ë¹„í™œì„±í™” ìƒíƒœë©´ ì¬ì‹œì‘ ë¶ˆí•„ìš”
    if (!localParticipant.isMicrophoneEnabled) {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] restartMicrophoneWithOptions: Microphone not enabled, skipping")
      }
      return true
    }

    try {
      setMediaError(null)

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] restartMicrophoneWithOptions: Restarting with options:", options)
      }

      // ë§ˆì´í¬ ë„ê¸°
      await localParticipant.setMicrophoneEnabled(false)

      // ì§§ì€ ì§€ì—° í›„ ìƒˆ ì˜µì…˜ìœ¼ë¡œ ë‹¤ì‹œ ì¼œê¸°
      await new Promise(resolve => setTimeout(resolve, 100))

      // ìƒˆ ì˜µì…˜ìœ¼ë¡œ ë§ˆì´í¬ í™œì„±í™”
      await localParticipant.setMicrophoneEnabled(true, {
        noiseSuppression: options.noiseSuppression,
        echoCancellation: options.echoCancellation,
        autoGainControl: options.autoGainControl,
        // voiceIsolationì€ ì¼ë¶€ ë¸Œë¼ìš°ì €ë§Œ ì§€ì›
        ...(options.voiceIsolation !== undefined && { voiceIsolation: options.voiceIsolation }),
        ...(options.deviceId && { deviceId: options.deviceId }),
      })

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] restartMicrophoneWithOptions: Successfully restarted")
      }

      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] restartMicrophoneWithOptions error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [localParticipant, parseMediaError])

  // ğŸ“Œ ì¹´ë©”ë¼ ì¥ì¹˜ ì „í™˜
  const switchCameraDevice = useCallback(async (deviceId: string): Promise<boolean> => {
    if (!room) {
      setMediaError({
        type: "not_connected",
        message: "LiveKitì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      })
      return false
    }

    try {
      setMediaError(null)
      await room.switchActiveDevice("videoinput", deviceId)
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Camera switched to:", deviceId)
      }
      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] Camera switch error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [room, parseMediaError])

  // ğŸ“Œ ë§ˆì´í¬ ì¥ì¹˜ ì „í™˜
  const switchMicrophoneDevice = useCallback(async (deviceId: string): Promise<boolean> => {
    if (!room) {
      setMediaError({
        type: "not_connected",
        message: "LiveKitì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      })
      return false
    }

    try {
      setMediaError(null)
      await room.switchActiveDevice("audioinput", deviceId)
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Microphone switched to:", deviceId)
      }
      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] Microphone switch error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [room, parseMediaError])

  // ğŸ“Œ ì¹´ë©”ë¼ ì„¤ì • ì¬ì ìš© (í•´ìƒë„/í”„ë ˆì„ë ˆì´íŠ¸ ë³€ê²½ ì‹œ ì¹´ë©”ë¼ ì¬ì‹œì‘)
  // LiveKitì˜ videoCaptureDefaultsëŠ” ë°© ì—°ê²° ì‹œì ì—ë§Œ ì ìš©ë˜ë¯€ë¡œ,
  // ì„¤ì • ë³€ê²½ ì‹œ ì¹´ë©”ë¼ë¥¼ ê»ë‹¤ ì¼œì„œ ìƒˆ ì„¤ì • ì ìš©
  const restartCamera = useCallback(async (): Promise<boolean> => {
    if (!localParticipant) {
      setMediaError({
        type: "not_connected",
        message: "LiveKitì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      })
      return false
    }

    const wasEnabled = localParticipant.isCameraEnabled
    if (!wasEnabled) {
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Camera not enabled, skip restart")
      }
      return true
    }

    try {
      setMediaError(null)
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Restarting camera with new settings...")
      }

      // 1. ì¹´ë©”ë¼ ë„ê¸°
      await localParticipant.setCameraEnabled(false)

      // 2. ì§§ì€ ë”œë ˆì´ (ì¥ì¹˜ í•´ì œ ëŒ€ê¸°)
      await new Promise(resolve => setTimeout(resolve, 100))

      // 3. ì¹´ë©”ë¼ ë‹¤ì‹œ ì¼œê¸° (ìƒˆ ì„¤ì •ì´ roomOptionsì—ì„œ ì ìš©ë¨)
      await localParticipant.setCameraEnabled(true)

      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Camera restarted successfully")
      }
      return true
    } catch (error) {
      console.error("[LiveKitMediaContext] Camera restart error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [localParticipant, parseMediaError])

  // Toggle screen share (with optional audio)
  const toggleScreenShare = useCallback(async (options?: ScreenShareOptions): Promise<boolean> => {
    if (!localParticipant) {
      setMediaError({
        type: "not_connected",
        message: "LiveKitì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
      })
      return false
    }

    try {
      setMediaError(null)

      const newState = !localParticipant.isScreenShareEnabled
      if (IS_DEV) {
        console.log("[LiveKitMediaContext] Toggle screen share:", newState ? "ON" : "OFF", options?.audio ? "(with audio)" : "")
      }

      // í™”ë©´ê³µìœ  ì‹œì‘ ì‹œ ì˜¤ë””ì˜¤ ì˜µì…˜ ì ìš©
      // ì°¸ê³ : ë¸Œë¼ìš°ì € íƒ­ ê³µìœ  ì‹œë§Œ ì˜¤ë””ì˜¤ ì§€ì›ë¨
      if (newState && options?.audio) {
        await localParticipant.setScreenShareEnabled(true, {
          audio: true,
          // ê³µìœ  ì¤‘ì¸ íƒ­ì˜ ë¡œì»¬ ì˜¤ë””ì˜¤ ì¬ìƒ ì–µì œ (ì—ì½” ë°©ì§€)
          suppressLocalAudioPlayback: true,
        })
      } else {
        await localParticipant.setScreenShareEnabled(newState)
      }
      return true
    } catch (error) {
      const errorName = error instanceof Error ? error.name : ""
      const errorMessage = error instanceof Error ? error.message : String(error)

      const isUserCancellation =
        errorName === "NotAllowedError" ||
        errorMessage.includes("Permission denied") ||
        errorMessage.includes("cancelled") ||
        errorMessage.includes("canceled")

      if (isUserCancellation) {
        if (IS_DEV) {
          console.log("[LiveKitMediaContext] Screen share cancelled by user")
        }
        return false
      }

      console.error("[LiveKitMediaContext] Screen share toggle error:", error)
      setMediaError(parseMediaError(error))
      return false
    }
  }, [localParticipant, parseMediaError])

  // Context value
  const value = useMemo<LiveKitMediaContextValue>(
    () => ({
      participantTracks,
      mediaState,
      mediaError,
      isAvailable: isConnected,
      localParticipantId: localParticipant?.identity ?? null,
      localAudioTrack,
      toggleCamera,
      toggleMicrophone,
      toggleScreenShare,
      setLocalMicrophoneMuted,
      setLocalAudioGated,
      replaceAudioTrackWithProcessed,
      restartMicrophoneWithOptions,
      switchCameraDevice,
      switchMicrophoneDevice,
      restartCamera,
    }),
    [
      participantTracks,
      mediaState,
      mediaError,
      isConnected,
      localParticipant?.identity,
      localAudioTrack,
      toggleCamera,
      toggleMicrophone,
      toggleScreenShare,
      setLocalMicrophoneMuted,
      setLocalAudioGated,
      replaceAudioTrackWithProcessed,
      restartMicrophoneWithOptions,
      switchCameraDevice,
      switchMicrophoneDevice,
      restartCamera,
    ]
  )

  return (
    <LiveKitMediaContext.Provider value={value}>
      {children}
    </LiveKitMediaContext.Provider>
  )
}
