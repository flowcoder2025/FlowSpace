"use client"

import { useRef, useEffect, useState, useCallback } from "react"
import { createPortal } from "react-dom"
import { cn } from "@/lib/utils"
import { Text, Button } from "@/components/ui"
import { useScreenRecorder } from "../../hooks"
import type { ParticipantTrack } from "../../livekit/types"

const IS_DEV = process.env.NODE_ENV === "development"

// ============================================
// Icons
// ============================================
const MicOffIcon = () => (
  <svg className="size-3" fill="currentColor" viewBox="0 0 20 20">
    <path fillRule="evenodd" d="M9.383 3.076A1 1 0 0110 4v12a1 1 0 01-1.707.707L4.586 13H2a1 1 0 01-1-1V8a1 1 0 011-1h2.586l3.707-3.707a1 1 0 011.09-.217zM12.293 7.293a1 1 0 011.414 0L15 8.586l1.293-1.293a1 1 0 111.414 1.414L16.414 10l1.293 1.293a1 1 0 01-1.414 1.414L15 11.414l-1.293 1.293a1 1 0 01-1.414-1.414L13.586 10l-1.293-1.293a1 1 0 010-1.414z" clipRule="evenodd" />
  </svg>
)

const CameraOffIcon = () => (
  <svg className="size-3" fill="currentColor" viewBox="0 0 20 20">
    <path fillRule="evenodd" d="M3.707 2.293a1 1 0 00-1.414 1.414l14 14a1 1 0 001.414-1.414l-1.473-1.473A10.014 10.014 0 0019.542 10C18.268 5.943 14.478 3 10 3a9.958 9.958 0 00-4.512 1.074l-1.78-1.781zm4.261 4.26l1.514 1.515a2.003 2.003 0 012.45 2.45l1.514 1.514a4 4 0 00-5.478-5.478z" clipRule="evenodd" />
    <path d="M12.454 16.697L9.75 13.992a4 4 0 01-3.742-3.742L2.335 6.578A9.98 9.98 0 00.458 10c1.274 4.057 5.065 7 9.542 7 .847 0 1.669-.105 2.454-.303z" />
  </svg>
)

const ScreenShareIcon = () => (
  <svg className="size-3" fill="currentColor" viewBox="0 0 20 20">
    <path d="M2 6a2 2 0 012-2h12a2 2 0 012 2v8a2 2 0 01-2 2H4a2 2 0 01-2-2V6zm14 0H4v8h12V6z" />
  </svg>
)

const SpeakingIcon = () => (
  <svg className="size-3 animate-pulse" fill="currentColor" viewBox="0 0 20 20">
    <path fillRule="evenodd" d="M9.383 3.076A1 1 0 0110 4v12a1 1 0 01-1.707.707L4.586 13H2a1 1 0 01-1-1V8a1 1 0 011-1h2.586l3.707-3.707a1 1 0 011.09-.217zM14.657 2.929a1 1 0 011.414 0A9.972 9.972 0 0119 10a9.972 9.972 0 01-2.929 7.071 1 1 0 01-1.414-1.414A7.971 7.971 0 0017 10c0-2.21-.894-4.208-2.343-5.657a1 1 0 010-1.414zm-2.829 2.828a1 1 0 011.415 0A5.983 5.983 0 0115 10a5.984 5.984 0 01-1.757 4.243 1 1 0 01-1.415-1.415A3.984 3.984 0 0013 10a3.983 3.983 0 00-1.172-2.828 1 1 0 010-1.415z" clipRule="evenodd" />
  </svg>
)

const AudioBlockedIcon = () => (
  <svg className="size-3" fill="currentColor" viewBox="0 0 20 20">
    <path fillRule="evenodd" d="M9.383 3.076A1 1 0 0110 4v12a1 1 0 01-1.707.707L4.586 13H2a1 1 0 01-1-1V8a1 1 0 011-1h2.586l3.707-3.707a1 1 0 011.09-.217zM12 7a1 1 0 011 1v4a1 1 0 11-2 0V8a1 1 0 011-1zm0 8a1 1 0 100-2 1 1 0 000 2z" clipRule="evenodd" />
  </svg>
)

const FullscreenIcon = () => (
  <svg className="size-3.5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 8V4m0 0h4M4 4l5 5m11-1V4m0 0h-4m4 0l-5 5M4 16v4m0 0h4m-4 0l5-5m11 5l-5-5m5 5v-4m0 4h-4" />
  </svg>
)

const ExitFullscreenIcon = () => (
  <svg className="size-3.5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 9V4.5M9 9H4.5M9 9L3.75 3.75M9 15v4.5M9 15H4.5M9 15l-5.25 5.25M15 9h4.5M15 9V4.5M15 9l5.25-5.25M15 15h4.5M15 15v4.5m0-4.5l5.25 5.25" />
  </svg>
)

const PipIcon = () => (
  <svg className="size-3.5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13 7h8m0 0v8m0-8l-8 8M3 17V7a2 2 0 012-2h6" />
    <rect x="3" y="13" width="8" height="6" rx="1" strokeWidth={2} />
  </svg>
)

const RecordIcon = () => (
  <svg className="size-3.5" fill="currentColor" viewBox="0 0 24 24">
    <circle cx="12" cy="12" r="8" />
  </svg>
)

const StopIcon = () => (
  <svg className="size-3.5" fill="currentColor" viewBox="0 0 24 24">
    <rect x="6" y="6" width="12" height="12" rx="1" />
  </svg>
)

const VolumeHighIcon = () => (
  <svg className="size-3.5" fill="currentColor" viewBox="0 0 24 24">
    <path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z" />
  </svg>
)

const VolumeLowIcon = () => (
  <svg className="size-3.5" fill="currentColor" viewBox="0 0 24 24">
    <path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02z" />
  </svg>
)

const VolumeMuteIcon = () => (
  <svg className="size-3.5" fill="currentColor" viewBox="0 0 24 24">
    <path d="M16.5 12c0-1.77-1.02-3.29-2.5-4.03v2.21l2.45 2.45c.03-.2.05-.41.05-.63zm2.5 0c0 .94-.2 1.82-.54 2.64l1.51 1.51C20.63 14.91 21 13.5 21 12c0-4.28-2.99-7.86-7-8.77v2.06c2.89.86 5 3.54 5 6.71zM4.27 3L3 4.27 7.73 9H3v6h4l5 5v-6.73l4.25 4.25c-.67.52-1.42.93-2.25 1.18v2.06c1.38-.31 2.63-.95 3.69-1.81L19.73 21 21 19.73l-9-9L4.27 3zM12 4L9.91 6.09 12 8.18V4z" />
  </svg>
)

/**
 * ë…¹í™” ì‹œê°„ í¬ë§· (MM:SS ë˜ëŠ” HH:MM:SS)
 */
function formatRecordingTime(seconds: number): string {
  const hrs = Math.floor(seconds / 3600)
  const mins = Math.floor((seconds % 3600) / 60)
  const secs = seconds % 60
  const pad = (n: number) => n.toString().padStart(2, "0")

  if (hrs > 0) {
    return `${pad(hrs)}:${pad(mins)}:${pad(secs)}`
  }
  return `${pad(mins)}:${pad(secs)}`
}

// ============================================
// VideoTile Props
// ============================================
interface VideoTileProps {
  track: ParticipantTrack
  isLocal?: boolean
  isScreenShare?: boolean  // í™”ë©´ê³µìœ  ì „ìš© íƒ€ì¼
  className?: string
  /** ğŸ¬ ë…¹í™” ê¶Œí•œ (ë³¸ì¸ í™”ë©´ ê³µìœ ì¼ ë•Œë§Œ ì ìš©) */
  canRecord?: boolean
  /** ğŸ·ï¸ ê³µê°„ ì´ë¦„ (ë…¹í™” íŒŒì¼ëª…ìš©) */
  spaceName?: string
  /** ğŸ¤ ëª¨ë“  ì°¸ê°€ìì˜ ì˜¤ë””ì˜¤ íŠ¸ë™ (ë…¹í™” ì‹œ ë¯¹ì‹±ìš©) */
  allAudioTracks?: MediaStreamTrack[]
  /** ğŸ”Š ì „ì—­ ì¶œë ¥ ë³¼ë¥¨ (0-100, ê°œë³„ ë³¼ë¥¨ê³¼ ê³±í•´ì§) */
  globalOutputVolume?: number
  /** ğŸª ë¡œì»¬ ë¹„ë””ì˜¤ ë¯¸ëŸ¬ ëª¨ë“œ */
  mirrorLocalVideo?: boolean
}

// ============================================
// VideoTile Component
// ============================================
export function VideoTile({
  track,
  isLocal = false,
  isScreenShare = false,
  className,
  canRecord = false,
  spaceName = "recording",
  allAudioTracks = [],
  globalOutputVolume = 100,
  mirrorLocalVideo = true,
}: VideoTileProps) {
  const videoRef = useRef<HTMLVideoElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const containerRef = useRef<HTMLDivElement>(null)
  const [audioBlocked, setAudioBlocked] = useState(false)
  const [isFullscreen, setIsFullscreen] = useState(false)
  const [isPipActive, setIsPipActive] = useState(false)
  const [showControls, setShowControls] = useState(false)

  // ğŸ”Š ë³¼ë¥¨ ìƒíƒœ (ì°¸ê°€ìë³„ localStorage ì €ì¥)
  const volumeStorageKey = `flow-volume-${track.participantId}`
  const [volume, setVolume] = useState(() => {
    if (typeof window === "undefined") return 1
    const saved = localStorage.getItem(volumeStorageKey)
    return saved ? parseFloat(saved) : 1
  })
  const [isMuted, setIsMuted] = useState(() => {
    if (typeof window === "undefined") return false
    const saved = localStorage.getItem(`${volumeStorageKey}-muted`)
    return saved === "true"
  })
  // ë³¼ë¥¨ë°”ëŠ” íƒ€ì¼ í˜¸ë²„ ì‹œ í•˜ë‹¨ì— í‘œì‹œ (showControlsë¡œ í†µí•©)

  // ğŸ¬ ë…¹í™” í›… (ë³¸ì¸ í™”ë©´ ê³µìœ ì¼ ë•Œë§Œ ì‚¬ìš©)
  const {
    recordingState,
    recordingTime,
    startRecording,
    stopRecording,
    error: recordingError,
    notification,
    clearNotification,
  } = useScreenRecorder({
    spaceName,
    notificationDuration: 4000, // 4ì´ˆ í›„ ìë™ ì‚¬ë¼ì§
    onError: (err) => {
      if (IS_DEV) {
        console.error("[VideoTile] Recording error:", err)
      }
    },
  })

  const isRecording = recordingState === "recording" || recordingState === "paused"
  // ğŸ”§ í™”ë©´ê³µìœ  ë…¹í™”: ë³¸ì¸/íƒ€ì¸ êµ¬ë¶„ ì—†ì´ ê¶Œí•œë§Œ ìˆìœ¼ë©´ ë…¹í™” ê°€ëŠ¥
  const showRecordButton = isScreenShare && canRecord

  // í™”ë©´ê³µìœ  ëª¨ë“œì¼ ë•ŒëŠ” screenTrack, ì•„ë‹ˆë©´ videoTrack ì‚¬ìš©
  const activeVideoTrack = isScreenShare ? track.screenTrack : track.videoTrack

  // ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ í•¨ìˆ˜ (ë³¼ë¥¨ë„ í•¨ê»˜ ì ìš©)
  // ğŸ“Œ ì „ì—­ ì¶œë ¥ ë³¼ë¥¨(globalOutputVolume)ê³¼ ê°œë³„ ë³¼ë¥¨ì„ ê³±í•¨
  const tryPlayAudio = useCallback(async () => {
    if (!audioRef.current || !track.audioTrack || isLocal) return

    // ê°œë³„ ë³¼ë¥¨ * ì „ì—­ ë³¼ë¥¨ (ë‘˜ ë‹¤ 0-1 ë²”ìœ„ë¡œ ë³€í™˜)
    const effectiveVolume = (volume * globalOutputVolume) / 100

    // ğŸ”§ ì¬ìƒ ì „ì— ë³¼ë¥¨ ë¨¼ì € ì„¤ì • (ë¸Œë¼ìš°ì €ì— ë”°ë¼ srcObject í›„ ì¦‰ì‹œ ì ìš© í•„ìš”)
    audioRef.current.volume = isMuted ? 0 : effectiveVolume

    try {
      await audioRef.current.play()
      setAudioBlocked(false)
      // ğŸ”§ ì¬ìƒ ì„±ê³µ í›„ì—ë„ ë³¼ë¥¨ ë‹¤ì‹œ í™•ì¸ ì ìš© (ì¼ë¶€ ë¸Œë¼ìš°ì € ì´ìŠˆ ëŒ€ì‘)
      audioRef.current.volume = isMuted ? 0 : effectiveVolume
      if (IS_DEV) {
        console.log("[VideoTile] Audio playback started for:", track.participantName, {
          volume: audioRef.current.volume,
          isMuted,
          globalOutputVolume,
        })
      }
    } catch (error) {
      // NotAllowedError = ë¸Œë¼ìš°ì € autoplay ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë¨
      if ((error as Error).name === "NotAllowedError") {
        console.warn("[VideoTile] Audio playback blocked by browser policy. Click anywhere to enable.")
        setAudioBlocked(true)
      } else {
        console.error("[VideoTile] Audio playback error:", error)
      }
    }
  }, [track.audioTrack, track.participantName, isLocal, volume, isMuted, globalOutputVolume])

  // ğŸ”§ ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ í´ë¦¬ì–´ í—¬í¼ (ë¸Œë¼ìš°ì € ë²„í¼ ì™„ì „ í•´ì œ)
  const clearVideoElement = useCallback((video: HTMLVideoElement) => {
    video.srcObject = null
    // ğŸ”§ load()ë¥¼ í˜¸ì¶œí•´ì•¼ ë¸Œë¼ìš°ì €ê°€ ë§ˆì§€ë§‰ í”„ë ˆì„ ë²„í¼ë¥¼ ì™„ì „íˆ í•´ì œ
    video.load()
  }, [])

  // ğŸ”§ íŠ¸ë™ì´ ì¡´ì¬í•˜ê³  ì•„ì§ live ìƒíƒœì´ë©° mutedê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ë¹„ë””ì˜¤ í‘œì‹œ
  // isVideoMuted/isScreenMuted í”Œë˜ê·¸ë¥¼ ìš°ì„  ì²´í¬í•˜ì—¬ mute ìƒíƒœì—ì„œ ë§ˆì§€ë§‰ í”„ë ˆì„ í‘œì‹œ ë°©ì§€
  // ğŸ”§ ë¡œì»¬ ì‚¬ìš©ìëŠ” muted ì²´í¬ ê±´ë„ˆëœ€ (ìì‹ ì˜ ì¹´ë©”ë¼ëŠ” í•­ìƒ í‘œì‹œ)
  const isTrackMuted = isScreenShare ? track.isScreenMuted : track.isVideoMuted

  // ğŸ”‘ í•µì‹¬ ê°œì„ : ì‹¤ì œ MediaStreamTrack ìƒíƒœê°€ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤
  // isTrackMuted í”Œë˜ê·¸ê°€ ë™ê¸°í™” ì§€ì—°ìœ¼ë¡œ ë¶€ì •í™•í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
  // íŠ¸ë™ì´ ì‹¤ì œë¡œ í™œì„± ìƒíƒœ(enabled + live)ì´ë©´ isTrackMuted ë¬´ì‹œ
  const isTrackActuallyLive = activeVideoTrack &&
    activeVideoTrack.enabled &&
    activeVideoTrack.readyState === "live"

  const shouldShowVideo = !!activeVideoTrack &&
    activeVideoTrack.readyState !== "ended" &&
    (isLocal || !isTrackMuted || isTrackActuallyLive)

  // Attach video track to video element
  // ğŸ”‘ mute ìƒíƒœ ë³€í™” ë° revision ë³€ê²½ë„ ì˜ì¡´ì„±ì— í¬í•¨í•˜ì—¬ ì¬ì‹¤í–‰
  useEffect(() => {
    const video = videoRef.current
    if (!video) return

    // íŠ¸ë™ì´ ì—†ê±°ë‚˜ muted ìƒíƒœë©´ ìŠ¤íŠ¸ë¦¼ í•´ì œ
    if (!shouldShowVideo) {
      clearVideoElement(video)
      if (IS_DEV) {
        console.log("[VideoTile] Clearing video for:", track.participantName, track.participantId, {
          hasTrack: !!activeVideoTrack,
          isTrackMuted,
          isTrackActuallyLive,
          shouldShowVideo,
          revision: track.revision,
        })
      }
      return
    }

    // ìƒˆ ìŠ¤íŠ¸ë¦¼ ì„¤ì • (cleanupì—ì„œ ì´ë¯¸ clearVideoElement í˜¸ì¶œí–ˆìœ¼ë¯€ë¡œ srcObject=null ë¶ˆí•„ìš”)
    const stream = new MediaStream([activeVideoTrack])
    video.srcObject = stream

    // ğŸ”§ ëª…ì‹œì  play() í˜¸ì¶œ - ê°™ì€ MediaStreamTrackì´ ì¬ì‚¬ìš©ë  ë•Œ autoPlayê°€ ë™ì‘í•˜ì§€ ì•ŠëŠ” ë¬¸ì œ í•´ê²°
    video.play().catch((err) => {
      // NotAllowedError: autoplay ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ (ì‚¬ìš©ì ì¸í„°ë™ì…˜ í•„ìš”)
      // AbortError: useEffect ì¬ì‹¤í–‰ìœ¼ë¡œ ì¸í•œ ì¤‘ë‹¨ (ì •ìƒ ë™ì‘)
      if (err.name !== "NotAllowedError" && err.name !== "AbortError") {
        console.error("[VideoTile] Video play error:", err)
      }
    })

    if (IS_DEV) {
      console.log("[VideoTile] Video track attached for:", track.participantName, track.participantId, {
        trackId: activeVideoTrack.id,
        enabled: activeVideoTrack.enabled,
        readyState: activeVideoTrack.readyState,
        isScreenShare,
        isTrackMuted,
        isTrackActuallyLive,
        revision: track.revision,
      })
    }

    // Handle track ended event (when remote user turns off camera)
    const handleTrackEnded = () => {
      if (IS_DEV) {
        console.log("[VideoTile] Video track ended for:", track.participantName)
      }
      // ğŸ”§ srcObjectë§Œ nullí•˜ë©´ ë¸Œë¼ìš°ì €ê°€ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ìœ ì§€í•  ìˆ˜ ìˆìŒ
      clearVideoElement(video)
    }

    activeVideoTrack.addEventListener("ended", handleTrackEnded)

    return () => {
      activeVideoTrack.removeEventListener("ended", handleTrackEnded)
      clearVideoElement(video)
    }
  }, [activeVideoTrack, shouldShowVideo, isTrackMuted, track.participantName, track.participantId, track.revision, isScreenShare, isTrackActuallyLive, clearVideoElement, isLocal])

  // Attach audio track to audio element (for remote participants only)
  // ğŸ“Œ ì „ì—­ ì¶œë ¥ ë³¼ë¥¨(globalOutputVolume)ê³¼ ê°œë³„ ë³¼ë¥¨ì„ ê³±í•¨
  useEffect(() => {
    const audio = audioRef.current
    if (!audio || isLocal) return

    if (track.audioTrack) {
      const stream = new MediaStream([track.audioTrack])
      audio.srcObject = stream

      // ê°œë³„ ë³¼ë¥¨ * ì „ì—­ ë³¼ë¥¨ (ë‘˜ ë‹¤ 0-1 ë²”ìœ„ë¡œ ë³€í™˜)
      const effectiveVolume = (volume * globalOutputVolume) / 100

      // ğŸ”§ ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì§í›„ ì €ì¥ëœ ë³¼ë¥¨ ì¦‰ì‹œ ì ìš©
      audio.volume = isMuted ? 0 : effectiveVolume

      if (IS_DEV) {
        console.log("[VideoTile] Audio track attached for:", track.participantName, {
          trackId: track.audioTrack.id,
          enabled: track.audioTrack.enabled,
          readyState: track.audioTrack.readyState,
          appliedVolume: audio.volume,
          globalOutputVolume,
        })
      }

      // ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ - defer to avoid synchronous setState in effect
      void Promise.resolve().then(() => {
        tryPlayAudio()
      })
    } else {
      audio.srcObject = null
      // Defer setState to avoid synchronous setState in effect
      void Promise.resolve().then(() => {
        setAudioBlocked(false)
      })
    }

    return () => {
      audio.srcObject = null
    }
  }, [track.audioTrack, track.participantName, isLocal, tryPlayAudio, volume, isMuted, globalOutputVolume])

  // ğŸ”§ ê°œì„ ëœ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ - once:true ì œê±°, ì§€ì†ì  ì¬ì‹œë„
  useEffect(() => {
    if (!audioBlocked) return

    const handleUserInteraction = () => {
      tryPlayAudio()
    }

    // ì‚¬ìš©ì ì¸í„°ë™ì…˜ ì‹œ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ (once ì œê±° - ì„±ê³µí•  ë•Œê¹Œì§€ ë°˜ë³µ ì‹œë„)
    // ğŸ“Œ touchstart/touchend ì¶”ê°€ - iOS Safariìš©
    document.addEventListener("click", handleUserInteraction)
    document.addEventListener("touchstart", handleUserInteraction, { passive: true })
    document.addEventListener("touchend", handleUserInteraction, { passive: true })
    document.addEventListener("keydown", handleUserInteraction)

    return () => {
      document.removeEventListener("click", handleUserInteraction)
      document.removeEventListener("touchstart", handleUserInteraction)
      document.removeEventListener("touchend", handleUserInteraction)
      document.removeEventListener("keydown", handleUserInteraction)
    }
  }, [audioBlocked, tryPlayAudio])

  // ğŸ“Œ iOS Safari: audioê°€ ì‹¤ì œë¡œ ì¬ìƒë˜ë©´ audioBlocked ìƒíƒœ ìë™ í•´ì œ
  useEffect(() => {
    const audio = audioRef.current
    if (!audio || isLocal) return

    const handlePlaying = () => {
      if (audioBlocked) {
        setAudioBlocked(false)
        if (IS_DEV) {
          console.log("[VideoTile] Audio now playing, clearing blocked state for:", track.participantName)
        }
      }
    }

    audio.addEventListener("playing", handlePlaying)
    return () => {
      audio.removeEventListener("playing", handlePlaying)
    }
  }, [audioBlocked, isLocal, track.participantName])

  // ğŸ”§ ëª…ì‹œì  ì˜¤ë””ì˜¤ í™œì„±í™” ë²„íŠ¼ í•¸ë“¤ëŸ¬
  const handleEnableAudio = useCallback((e: React.MouseEvent) => {
    e.stopPropagation()
    tryPlayAudio()
  }, [tryPlayAudio])

  // ğŸ”Š ë³¼ë¥¨/ìŒì†Œê±° í•¸ë“¤ëŸ¬
  const handleVolumeChange = useCallback((newVolume: number) => {
    setVolume(newVolume)
    localStorage.setItem(volumeStorageKey, newVolume.toString())
    // ë³¼ë¥¨ì„ ì˜¬ë¦¬ë©´ ìë™ìœ¼ë¡œ ìŒì†Œê±° í•´ì œ
    if (newVolume > 0 && isMuted) {
      setIsMuted(false)
      localStorage.setItem(`${volumeStorageKey}-muted`, "false")
    }
  }, [volumeStorageKey, isMuted])

  const handleToggleMute = useCallback((e: React.MouseEvent) => {
    e.stopPropagation()
    const newMuted = !isMuted
    setIsMuted(newMuted)
    localStorage.setItem(`${volumeStorageKey}-muted`, newMuted.toString())
  }, [isMuted, volumeStorageKey])


  // ğŸ”Š ë³¼ë¥¨/ìŒì†Œê±° ìƒíƒœë¥¼ ì˜¤ë””ì˜¤ ìš”ì†Œì— ì ìš©
  // ğŸ“Œ ì „ì—­ ì¶œë ¥ ë³¼ë¥¨(globalOutputVolume)ê³¼ ê°œë³„ ë³¼ë¥¨ì„ ê³±í•¨
  useEffect(() => {
    const audio = audioRef.current
    if (!audio || isLocal) return

    // ê°œë³„ ë³¼ë¥¨ * ì „ì—­ ë³¼ë¥¨ (ë‘˜ ë‹¤ 0-1 ë²”ìœ„ë¡œ ë³€í™˜)
    const effectiveVolume = (volume * globalOutputVolume) / 100
    audio.volume = isMuted ? 0 : effectiveVolume
  }, [volume, isMuted, isLocal, globalOutputVolume])

  // Fullscreen change detection
  useEffect(() => {
    const handleFullscreenChange = () => {
      setIsFullscreen(!!document.fullscreenElement)
    }
    document.addEventListener("fullscreenchange", handleFullscreenChange)
    return () => {
      document.removeEventListener("fullscreenchange", handleFullscreenChange)
    }
  }, [])

  // PIP change detection
  useEffect(() => {
    const video = videoRef.current
    if (!video) return

    const handleEnterPip = () => {
      setIsPipActive(true)
      if (IS_DEV) {
        console.log("[VideoTile] Entered PIP mode for:", track.participantName)
      }
    }
    const handleLeavePip = () => {
      setIsPipActive(false)
      if (IS_DEV) {
        console.log("[VideoTile] Left PIP mode for:", track.participantName)
      }
    }

    video.addEventListener("enterpictureinpicture", handleEnterPip)
    video.addEventListener("leavepictureinpicture", handleLeavePip)

    return () => {
      video.removeEventListener("enterpictureinpicture", handleEnterPip)
      video.removeEventListener("leavepictureinpicture", handleLeavePip)
    }
  }, [track.participantName])

  // Toggle fullscreen handler
  const handleToggleFullscreen = useCallback(async () => {
    if (!containerRef.current) return

    try {
      if (!document.fullscreenElement) {
        await containerRef.current.requestFullscreen()
      } else {
        await document.exitFullscreen()
      }
    } catch (error) {
      console.error("[VideoTile] Fullscreen toggle error:", error)
    }
  }, [])

  // Toggle PIP handler
  const handleTogglePip = useCallback(async () => {
    const video = videoRef.current
    if (!video) return

    try {
      if (document.pictureInPictureElement === video) {
        await document.exitPictureInPicture()
      } else if (document.pictureInPictureEnabled) {
        await video.requestPictureInPicture()
      }
    } catch (error) {
      console.error("[VideoTile] PIP toggle error:", error)
    }
  }, [])

  // ğŸ¬ ë…¹í™” ì‹œì‘/ì¤‘ì§€ í•¸ë“¤ëŸ¬ (ëª¨ë“  ì°¸ê°€ì ì˜¤ë””ì˜¤ ë¯¹ì‹±)
  const handleToggleRecording = useCallback(async () => {
    if (isRecording) {
      await stopRecording()
    } else if (track.screenTrack) {
      // ëª¨ë“  ì°¸ê°€ìì˜ ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ë¯¹ì‹±í•˜ì—¬ ë…¹í™”
      // allAudioTracksê°€ ë¹„ì–´ìˆìœ¼ë©´ í˜„ì¬ íŠ¸ë™ì˜ ì˜¤ë””ì˜¤ë§Œ ì‚¬ìš© (í´ë°±)
      const audioTracksToRecord = allAudioTracks.length > 0
        ? allAudioTracks
        : track.audioTrack ? [track.audioTrack] : []
      await startRecording(track.screenTrack, audioTracksToRecord)
    }
  }, [isRecording, track.screenTrack, track.audioTrack, allAudioTracks, startRecording, stopRecording])

  // hasAudio, isAudioMuted, canPipëŠ” ë Œë”ë§ì—ì„œë§Œ ì‚¬ìš©
  const hasAudio = !!track.audioTrack
  const isAudioMuted = track.isAudioMuted ?? !hasAudio
  // ğŸ”§ ë¡œì»¬ ë¹„ë””ì˜¤ì—ì„œë„ PIP í—ˆìš© (ìì‹ ì˜ ë¹„ë””ì˜¤ë¥¼ PIPë¡œ ë³¼ ìˆ˜ ìˆë„ë¡)
  const canPip = shouldShowVideo && document.pictureInPictureEnabled

  return (
    <div
      ref={containerRef}
      className={cn(
        "group relative aspect-video rounded-lg bg-black",
        // ì „ì²´í™”ë©´ì´ ì•„ë‹ ë•Œë§Œ overflow-hidden (Portalì´ ì˜ë¦¬ì§€ ì•Šë„ë¡)
        !isFullscreen && "overflow-hidden",
        track.isSpeaking && "ring-2 ring-primary ring-offset-2",
        isFullscreen && "fixed inset-0 z-50 aspect-auto rounded-none",
        className
      )}
      onMouseEnter={() => setShowControls(true)}
      onMouseLeave={() => setShowControls(false)}
    >
      {/* Video element - ğŸ”‘ í•­ìƒ ë Œë”ë§í•˜ì—¬ adaptiveStreamì´ íŠ¸ë™ì„ í™œì„±í™”í•  ìˆ˜ ìˆê²Œ í•¨ */}
      {/* hidden(display:none) ëŒ€ì‹  opacity-0 + absoluteë¡œ ìˆ¨ê¹€ - IntersectionObserverê°€ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ */}
      {/* ğŸ”§ absolute z-0: ì „ì²´í™”ë©´ ì‹œ Portalë¡œ ë Œë”ë§ë˜ëŠ” ì±„íŒ… ì˜¤ë²„ë ˆì´(z-max)ê°€ ìœ„ì— í‘œì‹œë˜ë„ë¡ */}
      {/* z-indexëŠ” positioned ìš”ì†Œ(relative/absolute/fixed)ì—ë§Œ ì ìš©ë¨ */}
      {/* ğŸª ë¡œì»¬ ë¹„ë””ì˜¤ + ë¯¸ëŸ¬ ëª¨ë“œ + ì¼ë°˜ ë¹„ë””ì˜¤(í™”ë©´ê³µìœ  ì œì™¸)ì¼ ë•Œ ì¢Œìš° ë°˜ì „ */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted={isLocal} // Mute local video to prevent feedback
        className={cn(
          "absolute inset-0 size-full z-0",
          // ğŸ”§ í™”ë©´ ê³µìœ ëŠ” object-contain (ì˜ë¦¬ì§€ ì•ŠìŒ), ì¼ë°˜ ë¹„ë””ì˜¤ëŠ” object-cover (ê½‰ ì±„ì›€)
          isScreenShare ? "object-contain bg-black" : "object-cover",
          !shouldShowVideo && "opacity-0 pointer-events-none",
          // ğŸª ë¯¸ëŸ¬ ëª¨ë“œ: ë¡œì»¬ + ì¼ë°˜ ë¹„ë””ì˜¤(í™”ë©´ê³µìœ  ì œì™¸) + mirrorLocalVideo í™œì„±í™”
          isLocal && !isScreenShare && mirrorLocalVideo && "scale-x-[-1]"
        )}
      />

      {/* Placeholder - ë¹„ë””ì˜¤ê°€ ì—†ì„ ë•Œë§Œ í‘œì‹œ (ìƒˆ ì•„ë°”íƒ€ ì´ë¯¸ì§€ + ìƒ‰ìƒ í•„í„°) */}
      {!shouldShowVideo && (
        <div className="flex size-full items-center justify-center bg-black">
          {/* ì•„ë°”íƒ€ ìƒ‰ìƒì— ë”°ë¥¸ hue-rotate í•„í„° ì ìš© */}
          {/* ì›ë³¸ ì´ë¯¸ì§€: ì²­ë¡ìƒ‰(teal, ~180Â° hue) */}
          <img
            src="/Game.png"
            alt={track.participantName}
            className="size-20 object-contain"
            style={{
              filter: (() => {
                // ì›ë³¸ ì²­ë¡ìƒ‰(180Â°)ì—ì„œ ëª©í‘œ ìƒ‰ìƒìœ¼ë¡œ íšŒì „
                const hueMap: Record<string, number> = {
                  default: 0,     // ì²­ë¡ìƒ‰ ìœ ì§€
                  red: 180,       // ë¹¨ê°•(0Â°): 180Â° íšŒì „
                  green: -60,     // ì´ˆë¡(120Â°): -60Â° íšŒì „
                  purple: 90,     // ë³´ë¼(270Â°): 90Â° íšŒì „
                  orange: -150,   // ì£¼í™©(30Â°): -150Â° íšŒì „
                  pink: 150,      // í•‘í¬(330Â°): 150Â° íšŒì „
                }
                const hue = hueMap[track.avatarColor || "default"] ?? 0
                return hue !== 0 ? `hue-rotate(${hue}deg)` : undefined
              })(),
            }}
          />
        </div>
      )}

      {/* Audio element (hidden, for remote participants) */}
      {!isLocal && (
        <audio ref={audioRef} autoPlay playsInline className="hidden" />
      )}

      {/* ğŸ”´ ë…¹í™” ì¤‘ í‘œì‹œ - í™”ë©´ ì¢Œìƒë‹¨ */}
      {isRecording && (
        <div className="absolute left-2 top-2 flex items-center gap-2 rounded-md bg-red-600/90 px-2 py-1 text-white shadow-lg">
          <div className="size-2 animate-pulse rounded-full bg-white" />
          <Text size="xs" className="font-medium tracking-wider">
            REC {formatRecordingTime(recordingTime)}
          </Text>
        </div>
      )}

      {/* ğŸ¬ OSD ì•Œë¦¼ (ìë™ ì‚¬ë¼ì§)
          - ì „ì²´í™”ë©´: ì „ì²´í™”ë©´ ì •ì¤‘ì•™ì— í‘œì‹œ
          - ì¼ë°˜ íƒ€ì¼: Portalë¡œ ê²Œì„ íŒ¨ë„(#game-panel) ì •ì¤‘ì•™ì— í‘œì‹œ
      */}
      {notification && (() => {
        const osdContent = (
          <div
            className={cn(
              "flex items-center justify-between gap-2 rounded-md px-3 py-2 text-white shadow-lg backdrop-blur-sm transition-all duration-300",
              notification.type === "success" && "bg-green-600/90",
              notification.type === "info" && "bg-blue-600/90",
              notification.type === "error" && "bg-red-600/90",
              // ì „ì²´í™”ë©´: ìƒë‹¨ ì¤‘ì•™ (ê¸°ì¡´ ìœ„ì¹˜)
              isFullscreen && "absolute left-1/2 top-1/2 z-20 -translate-x-1/2 -translate-y-1/2",
              // ì¼ë°˜ íƒ€ì¼: Portal íƒ€ê²Ÿ ë‚´ì—ì„œ ì •ì¤‘ì•™
              !isFullscreen && "fixed left-1/2 top-1/2 z-9999 -translate-x-1/2 -translate-y-1/2"
            )}
          >
            <Text size="xs" className="font-medium">
              {notification.message}
            </Text>
            <button
              onClick={clearNotification}
              className="shrink-0 rounded p-0.5 hover:bg-white/20"
              aria-label="ì•Œë¦¼ ë‹«ê¸°"
            >
              <svg className="size-3" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          </div>
        )

        // ì „ì²´í™”ë©´: VideoTile ë‚´ë¶€ì— ë Œë”ë§
        if (isFullscreen) {
          return osdContent
        }

        // ì¼ë°˜ íƒ€ì¼: ê²Œì„ íŒ¨ë„ì— Portalë¡œ ë Œë”ë§
        const gamePanel = typeof document !== "undefined" ? document.getElementById("game-panel") : null
        if (gamePanel) {
          return createPortal(osdContent, gamePanel)
        }

        // í´ë°±: ê·¸ëƒ¥ ë Œë”ë§
        return osdContent
      })()}

      {/* ë…¹í™” ì—ëŸ¬ í‘œì‹œ (ì˜êµ¬ - ëª…ì‹œì  í™•ì¸ í•„ìš”) */}
      {recordingError && !notification && (
        <div className="absolute inset-x-2 top-10 z-10 rounded-md bg-red-600/90 px-3 py-2 text-white shadow-lg">
          <Text size="xs">{recordingError}</Text>
        </div>
      )}

      {/* Video controls overlay (top-right) - visible on hover */}
      {/* ğŸ”§ ë¹„ë””ì˜¤ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ í•­ìƒ ë Œë”ë§ (ì „ì²´í™”ë©´ì€ ë¹„ë””ì˜¤ ì—†ì´ë„ ê°€ëŠ¥) */}
      <div
        className={cn(
          "absolute right-2 top-2 flex items-center gap-1 transition-opacity duration-200",
          showControls || isFullscreen ? "opacity-100" : "opacity-0"
        )}
      >
        {/* ğŸ¬ ë…¹í™” ë²„íŠ¼ - ë³¸ì¸ í™”ë©´ ê³µìœ ì¼ ë•Œë§Œ í‘œì‹œ */}
        {showRecordButton && (
          <Button
            variant="ghost"
            size="sm"
            onClick={handleToggleRecording}
            disabled={recordingState === "stopping"}
            className={cn(
              "size-7 p-0 hover:bg-white/20",
              isRecording ? "text-white bg-red-600/80 hover:bg-red-600" : "text-red-500"
            )}
            title={isRecording ? "ë…¹í™” ì¤‘ì§€" : "ë…¹í™” ì‹œì‘"}
            aria-label={isRecording ? "í™”ë©´ ë…¹í™” ì¤‘ì§€" : "í™”ë©´ ë…¹í™” ì‹œì‘"}
          >
            {isRecording ? <StopIcon /> : <RecordIcon />}
          </Button>
        )}
        {/* PIP Button - ë¹„ë””ì˜¤ê°€ ìˆì„ ë•Œë§Œ */}
        {canPip && (
          <button
            onClick={handleTogglePip}
            className={cn(
              "rounded bg-black/60 p-1.5 text-white transition-colors hover:bg-black/80",
              isPipActive && "bg-primary/80 hover:bg-primary/90"
            )}
            title={isPipActive ? "PIP ì¢…ë£Œ" : "PIP ëª¨ë“œ"}
            aria-label={isPipActive ? "PIP ëª¨ë“œ ì¢…ë£Œ" : "PIP ëª¨ë“œ ì‹œì‘"}
          >
            <PipIcon />
          </button>
        )}
        {/* Fullscreen Button - í•­ìƒ í‘œì‹œ */}
        <button
          onClick={handleToggleFullscreen}
          className="rounded bg-black/60 p-1.5 text-white transition-colors hover:bg-black/80"
          title={isFullscreen ? "ì „ì²´í™”ë©´ ì¢…ë£Œ" : "ì „ì²´í™”ë©´"}
          aria-label={isFullscreen ? "ì „ì²´í™”ë©´ ì¢…ë£Œ" : "ì „ì²´í™”ë©´ìœ¼ë¡œ ë³´ê¸°"}
        >
          {isFullscreen ? <ExitFullscreenIcon /> : <FullscreenIcon />}
        </button>
      </div>

      {/* Overlay info (bottom) */}
      <div className="absolute inset-x-0 bottom-0 bg-linear-to-t from-black/70 to-transparent p-2">
        {/* ğŸ”Š ë³¼ë¥¨ë°” - ì›ê²© ì°¸ê°€ì + í˜¸ë²„ ì‹œì—ë§Œ í‘œì‹œ */}
        {!isLocal && hasAudio && (
          <div
            className={cn(
              "mb-2 flex items-center gap-2 transition-all duration-200",
              showControls ? "opacity-100 translate-y-0" : "opacity-0 translate-y-2 pointer-events-none"
            )}
          >
            <button
              onClick={handleToggleMute}
              className="shrink-0 text-white/80 hover:text-white transition-colors"
              title={isMuted ? "ìŒì†Œê±° í•´ì œ" : "ìŒì†Œê±°"}
              aria-label={isMuted ? "ìŒì†Œê±° í•´ì œ" : "ìŒì†Œê±°"}
            >
              {isMuted ? <VolumeMuteIcon /> : volume > 0.5 ? <VolumeHighIcon /> : <VolumeLowIcon />}
            </button>
            <input
              type="range"
              min="0"
              max="1"
              step="0.05"
              value={isMuted ? 0 : volume}
              onChange={(e) => handleVolumeChange(parseFloat(e.target.value))}
              className="h-1 w-full cursor-pointer appearance-none rounded-full bg-white/30 accent-primary
                [&::-webkit-slider-thumb]:size-3 [&::-webkit-slider-thumb]:appearance-none
                [&::-webkit-slider-thumb]:rounded-full [&::-webkit-slider-thumb]:bg-white
                [&::-webkit-slider-thumb]:shadow-md [&::-webkit-slider-thumb]:transition-transform
                [&::-webkit-slider-thumb]:hover:scale-125
                [&::-moz-range-thumb]:size-3 [&::-moz-range-thumb]:rounded-full
                [&::-moz-range-thumb]:border-0 [&::-moz-range-thumb]:bg-white"
              title={`ë³¼ë¥¨: ${Math.round((isMuted ? 0 : volume) * 100)}%`}
              aria-label="ë³¼ë¥¨ ì¡°ì ˆ"
              onClick={(e) => e.stopPropagation()}
            />
            <span className="shrink-0 w-8 text-xs text-white/80 text-right">
              {Math.round((isMuted ? 0 : volume) * 100)}%
            </span>
          </div>
        )}
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-1.5">
            {track.isSpeaking && (
              <div className="rounded bg-primary/80 p-0.5 text-white">
                <SpeakingIcon />
              </div>
            )}
            <Text size="xs" className="truncate text-white">
              {track.participantName}
              {isLocal && " (ë‚˜)"}
              {isScreenShare && " - í™”ë©´ê³µìœ "}
            </Text>
          </div>
          <div className="flex items-center gap-1">
            {audioBlocked && (
              <button
                onClick={handleEnableAudio}
                className="flex items-center gap-1 rounded bg-warning/90 px-1.5 py-0.5 text-xs font-medium text-white transition-colors hover:bg-warning"
                title="í´ë¦­í•˜ì—¬ ì˜¤ë””ì˜¤ í™œì„±í™”"
                aria-label="ì˜¤ë””ì˜¤ í™œì„±í™”"
              >
                <AudioBlockedIcon />
                <span>ì†Œë¦¬ ì¼œê¸°</span>
              </button>
            )}
            {isAudioMuted && (
              <div className="rounded bg-destructive/80 p-0.5 text-white">
                <MicOffIcon />
              </div>
            )}
            {!shouldShowVideo && (
              <div className="rounded bg-muted-foreground/80 p-0.5 text-white">
                <CameraOffIcon />
              </div>
            )}
            {track.screenTrack && (
              <div className="rounded bg-primary/80 p-0.5 text-white">
                <ScreenShareIcon />
              </div>
            )}
          </div>
        </div>
      </div>
    </div>
  )
}
